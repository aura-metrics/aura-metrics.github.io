<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AURA — DORA for pipelines. AURA for agents.</title>
<meta name="description" content="AURA: Five key metrics for AI agent performance, built on OpenTelemetry. DORA for pipelines. AURA for agents.">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,400;0,500;0,600;1,400;1,500&family=DM+Mono:wght@400;500&family=Outfit:wght@300;400;500;600&display=swap" rel="stylesheet">
<style>
:root {
  --bg: #08080c;
  --bg-raised: #0e0e14;
  --bg-card: #12121a;
  --bg-card-hover: #181822;
  --border: #222233;
  --border-subtle: #181828;
  --text: #e4e2ef;
  --text-muted: #9490a8;
  --text-dim: #5c5872;
  --glow: #4ADE80;
  --glow-bright: #6EE7A0;
  --glow-dim: #22C55E;
  --glow-bg: rgba(74, 222, 128, 0.05);
  --glow-bg-strong: rgba(74, 222, 128, 0.10);
  --warm: #ffd6a0;
  --red: #ff6b8a;
  --green: #7aefb2;
  --blue: #7ab8ef;
  --serif: 'Cormorant Garamond', Georgia, serif;
  --sans: 'Outfit', -apple-system, sans-serif;
  --mono: 'DM Mono', 'SF Mono', monospace;
}

*, *::before, *::after { margin: 0; padding: 0; box-sizing: border-box; }
html { scroll-behavior: smooth; -webkit-font-smoothing: antialiased; scroll-padding-top: 100px; }

body {
  font-family: var(--sans);
  background: var(--bg);
  color: var(--text);
  line-height: 1.65;
  font-size: 16px;
  overflow-x: hidden;
  padding-top: 98px;
}

::selection { background: var(--glow); color: var(--bg); }

.container { max-width: 1100px; margin: 0 auto; padding: 0 32px; }
section { padding: 100px 0; position: relative; }
section + section { border-top: 1px solid var(--border-subtle); }

h1, h2, h3 { font-family: var(--serif); font-weight: 400; }
h1 { font-size: clamp(3.2rem, 8vw, 6rem); line-height: 1.05; letter-spacing: -0.02em; }
h2 { font-size: clamp(2rem, 4vw, 3.2rem); line-height: 1.15; margin-bottom: 20px; letter-spacing: -0.01em; }
h3 { font-size: 1.5rem; line-height: 1.3; margin-bottom: 12px; }
p { color: var(--text-muted); font-size: 1.05rem; max-width: 620px; font-weight: 300; }
p + p { margin-top: 16px; }

.label {
  font-family: var(--mono);
  font-size: 0.7rem;
  letter-spacing: 0.14em;
  text-transform: uppercase;
  color: var(--glow-dim);
  margin-bottom: 16px;
  display: block;
}

/* ── Draft banner ── */
.draft-banner {
  position: fixed; top: 0; left: 0; right: 0; z-index: 200;
  background: rgba(74,222,128,0.08); border-bottom: 1px solid var(--glow-dim);
  padding: 10px 32px; display: flex; align-items: center; justify-content: center; gap: 16px;
  font-family: var(--mono); font-size: 0.72rem; color: var(--text-muted);
}
.draft-banner strong { color: var(--glow); }
.draft-banner a { color: var(--glow-dim); text-decoration: none; border-bottom: 1px solid var(--glow-dim); transition: color 0.2s; }
.draft-banner a:hover { color: var(--glow); }

/* ── Nav ── */
nav {
  position: fixed; top: 41px; left: 0; right: 0; z-index: 100;
  padding: 16px 32px;
  display: flex; justify-content: space-between; align-items: center;
  background: rgba(8,8,12,0.88); backdrop-filter: blur(16px);
  border-bottom: 1px solid var(--border-subtle);
}
nav .logo {
  font-family: var(--serif); font-size: 1.3rem; font-weight: 500;
  color: var(--text); text-decoration: none;
}
nav .logo span { color: var(--glow); }
nav .nav-links { display: flex; gap: 0; list-style: none; position: absolute; left: 50%; transform: translateX(-50%); align-items: center; }
nav .nav-links li { display: flex; align-items: center; }
nav .nav-links li + li::before { content: '|'; color: var(--border); padding: 0 16px; }
nav .nav-links a {
  font-family: var(--mono); font-size: 0.72rem; color: var(--text-dim);
  text-decoration: none; letter-spacing: 0.05em; transition: color 0.2s;
}
nav .nav-links a:hover { color: var(--glow); }
nav .nav-github {
  font-family: var(--mono); font-size: 0.72rem; color: var(--text-dim);
  text-decoration: none; letter-spacing: 0.05em; transition: color 0.2s;
  display: flex; align-items: center; gap: 6px;
}
nav .nav-github:hover { color: var(--glow); }
nav .nav-github svg { width: 15px; height: 15px; fill: currentColor; }

/* ── Hero ── */
.hero {
  min-height: 100vh; display: flex; flex-direction: column;
  justify-content: center; padding: 120px 0 80px; position: relative;
}
.hero::before {
  content: ''; position: absolute;
  top: 10%; left: 50%; transform: translateX(-50%);
  width: 800px; height: 800px;
  background: radial-gradient(circle, rgba(74,222,128,0.06) 0%, rgba(74,222,128,0.02) 30%, transparent 70%);
  pointer-events: none;
}
.hero::after {
  content: ''; position: absolute;
  bottom: 0; left: 0; right: 0; height: 1px;
  background: linear-gradient(90deg, transparent, var(--glow-dim), transparent);
  opacity: 0.3;
}

.hero-eyebrow {
  font-family: var(--mono); font-size: 0.78rem;
  color: var(--glow-dim); letter-spacing: 0.08em;
  margin-bottom: 32px;
}

h1 .glow {
  color: var(--glow);
  text-shadow: 0 0 60px rgba(74,222,128,0.25);
}

.hero-sub {
  font-family: var(--serif); font-size: 1.45rem; font-style: italic;
  color: var(--text-muted); max-width: 520px; line-height: 1.5;
  margin: 28px 0 48px; font-weight: 400;
}

.hero-cta { display: flex; gap: 16px; flex-wrap: wrap; }

.btn {
  display: inline-flex; align-items: center; gap: 8px;
  padding: 14px 28px; border-radius: 6px;
  font-family: var(--mono); font-size: 0.8rem;
  text-decoration: none; letter-spacing: 0.03em;
  transition: all 0.25s ease; cursor: pointer; border: none;
}
.btn-primary {
  background: var(--glow); color: var(--bg);
}
.btn-primary:hover {
  background: var(--glow-bright);
  box-shadow: 0 4px 32px rgba(74,222,128,0.3);
  transform: translateY(-1px);
}
.btn-ghost {
  background: transparent; color: var(--text-muted);
  border: 1px solid var(--border);
}
.btn-ghost:hover { border-color: var(--glow-dim); color: var(--glow); }

/* ── Problem ── */
.problem-grid {
  display: grid; grid-template-columns: 1fr 1fr;
  gap: 20px; margin-top: 48px;
}
.problem-card {
  padding: 32px; border: 1px solid var(--border-subtle);
  border-radius: 10px; background: var(--bg-card);
  transition: border-color 0.3s;
}
.problem-card:hover { border-color: var(--border); }
.problem-card .num {
  font-family: var(--mono); font-size: 0.65rem;
  color: var(--text-dim); letter-spacing: 0.12em; margin-bottom: 16px;
}
.problem-card h3 { color: var(--text); font-family: var(--sans); font-weight: 500; font-size: 1.05rem; }
.problem-card p { font-size: 0.92rem; color: var(--text-dim); margin-top: 8px; }

/* ── Insight ── */
.insight-box {
  background: var(--bg-card); border: 1px solid var(--border);
  border-radius: 14px; padding: 56px; margin-top: 48px;
  position: relative; overflow: hidden;
}
.insight-box::before {
  content: ''; position: absolute; top: 0; left: 0; right: 0; height: 1px;
  background: linear-gradient(90deg, transparent, var(--glow), transparent);
}
.insight-box h3 { font-size: 1.9rem; color: var(--text); margin-bottom: 20px; max-width: 560px; }
.hierarchy {
  margin-top: 36px; font-family: var(--mono); font-size: 0.82rem;
  line-height: 2; color: var(--text-muted);
  background: var(--bg); border-radius: 8px; padding: 24px 28px;
  border: 1px solid var(--border-subtle);
}
.hierarchy .hl { color: var(--glow); }
.hierarchy .dim { color: var(--text-dim); }

/* ── Metrics ── */
.metrics-header { text-align: left; margin: 0 0 64px; }
.metrics-header p { margin: 0; }

.metrics-grid {
  display: grid; grid-template-columns: repeat(3, 1fr);
  gap: 1px; background: var(--border-subtle);
  border-radius: 14px; overflow: hidden;
}
.metrics-grid.two-col {
  grid-template-columns: repeat(2, 1fr);
  max-width: 733px; margin: 1px auto 0;
}
.metric-card {
  background: var(--bg-card); padding: 36px 32px;
  transition: background 0.2s;
}
.metric-card:hover { background: var(--bg-card-hover); }
.metric-number {
  font-family: var(--mono); font-size: 0.62rem;
  color: var(--text-dim); letter-spacing: 0.15em;
  text-transform: uppercase; margin-bottom: 18px;
}
.metric-name {
  font-family: var(--serif); font-size: 1.55rem;
  color: var(--text); margin-bottom: 4px;
}
.metric-analog {
  font-family: var(--mono); font-size: 0.7rem;
  color: var(--glow-dim); margin-bottom: 14px;
}
.metric-desc {
  font-size: 0.9rem; color: var(--text-dim);
  line-height: 1.55; max-width: 100%;
}
.tiers { margin-top: 18px; display: flex; flex-direction: column; gap: 5px; }
.tier {
  display: flex; justify-content: space-between; align-items: center;
  font-family: var(--mono); font-size: 0.7rem;
}
.tier-label { color: var(--text-dim); }
.tier-value { color: var(--text-muted); }
.tier.elite .tier-label { color: var(--glow); }
.tier.elite .tier-value { color: var(--glow); }

/* ── Conformance dimensions ── */
.dimension-grid {
  display: grid; grid-template-columns: repeat(4, 1fr);
  gap: 1px; background: var(--border-subtle);
  border-radius: 10px; overflow: hidden; margin-top: 32px;
}
.dimension { background: var(--bg-card); padding: 28px 20px; text-align: center; }
.dimension-weight { font-family: var(--serif); font-size: 2.2rem; color: var(--glow); margin-bottom: 4px; }
.dimension-name { font-size: 0.85rem; font-weight: 500; color: var(--text); margin-bottom: 8px; }
.dimension-desc { font-size: 0.78rem; color: var(--text-dim); line-height: 1.4; }

/* ── Comparison ── */
.comparison { margin-top: 48px; overflow-x: auto; }
.comparison table { width: 100%; border-collapse: collapse; font-size: 0.9rem; }
.comparison th {
  font-family: var(--mono); font-size: 0.68rem; letter-spacing: 0.1em;
  text-transform: uppercase; color: var(--text-dim); text-align: left;
  padding: 14px 20px; border-bottom: 1px solid var(--border);
}
.comparison td {
  padding: 14px 20px; border-bottom: 1px solid var(--border-subtle);
  color: var(--text-muted); vertical-align: top; font-weight: 300;
}
.comparison tr td:first-child { color: var(--text); font-weight: 400; }
.comparison .glow-cell { color: var(--glow); }

/* ── Architecture ── */
.arch-pipeline { display: flex; flex-direction: column; align-items: flex-start; margin-top: 48px; width: fit-content; }
.arch-step { display: grid; grid-template-columns: 150px auto; align-items: center; gap: 28px; }
.arch-step .tag {
  font-family: var(--mono); font-size: 0.7rem;
  padding: 5px 12px; border-radius: 4px; white-space: nowrap; text-align: center;
}
.arch-step .tag.you  { background: rgba(74,222,128,0.10); color: var(--glow); }
.arch-step .tag.aura { background: rgba(74,222,128,0.10); color: var(--glow); }
.arch-step .tag.otel { background: rgba(122,184,239,0.10); color: var(--blue); }
.arch-step .tag.infra { background: rgba(122,239,178,0.10); color: var(--green); }
.arch-step .desc { font-size: 0.88rem; color: var(--text-muted); font-weight: 300; }
.arch-conn {
  height: 36px; width: 2px; margin-left: 74px;
  background: linear-gradient(to bottom, rgba(74,222,128,0.15), rgba(74,222,128,0.55));
  box-shadow: 0 0 8px rgba(74,222,128,0.25);
}

/* ── Philosophy ── */
.principles { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 48px; }
.principle {
  padding: 28px 32px; border-left: 2px solid var(--border-subtle);
  transition: border-color 0.3s;
}
.principle:hover { border-color: var(--glow); }
.principle-num {
  font-family: var(--mono); font-size: 0.62rem;
  color: var(--glow-dim); letter-spacing: 0.12em; margin-bottom: 12px;
}
.principle h3 { font-family: var(--sans); font-size: 1rem; font-weight: 500; color: var(--text); margin-bottom: 8px; }
.principle p { font-size: 0.9rem; color: var(--text-dim); }

/* ── CTA ── */
.cta-section { text-align: center; padding: 120px 0; position: relative; }
.cta-section::before {
  content: ''; position: absolute;
  top: 50%; left: 50%; transform: translate(-50%, -50%);
  width: 600px; height: 400px;
  background: radial-gradient(ellipse, rgba(74,222,128,0.04) 0%, transparent 70%);
  pointer-events: none;
}
.cta-section h2 { margin-bottom: 16px; }
.cta-section p { margin: 0 auto 40px; text-align: center; }
.cta-actions { display: flex; justify-content: center; gap: 16px; flex-wrap: wrap; }

/* ── Implementation ── */
.plugins-grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(320px, 1fr)); gap: 1px; background: var(--border-subtle); border-radius: 14px; overflow: hidden; margin-top: 48px; }
.plugin-card { background: var(--bg-card); padding: 36px 32px; transition: background 0.2s; }
.plugin-card:hover { background: var(--bg-card-hover); }
.plugin-card-label { font-family: var(--mono); font-size: 0.62rem; color: var(--text-dim); letter-spacing: 0.15em; text-transform: uppercase; margin-bottom: 14px; }
.plugin-card h3 { font-family: var(--serif); font-size: 1.4rem; color: var(--text); margin-bottom: 10px; }
.plugin-card p { font-size: 0.9rem; color: var(--text-dim); line-height: 1.55; margin-bottom: 24px; }
.plugin-card a.plugin-link { font-family: var(--mono); font-size: 0.72rem; color: var(--glow); text-decoration: none; letter-spacing: 0.05em; transition: opacity 0.2s; display: inline-flex; align-items: center; gap: 6px; }
.plugin-card a.plugin-link:hover { opacity: 0.75; }

/* ── Footer ── */
footer { border-top: 1px solid var(--border-subtle); padding: 40px 0; text-align: center; }
footer p { font-size: 0.85rem; color: var(--text-dim); margin: 0 auto; }
footer a { color: var(--text-muted); text-decoration: none; }
footer a:hover { color: var(--glow); }

/* ── Specification ── */
.spec-section { background: var(--bg-raised); }
.spec-nav { display: flex; flex-wrap: wrap; gap: 0; margin: 32px 0 0; border-bottom: 1px solid var(--border-subtle); }
.spec-nav button {
  font-family: var(--mono); font-size: 0.72rem; color: var(--text-dim);
  background: none; border: none; border-bottom: 2px solid transparent;
  cursor: pointer; padding: 10px 16px; margin-bottom: -1px;
  letter-spacing: 0.05em; transition: color 0.2s, border-color 0.2s; white-space: nowrap;
}
.spec-nav button:hover { color: var(--text); }
.spec-nav button.active { color: var(--glow); border-bottom-color: var(--glow); }
.spec-block { display: none; padding-top: 48px; }
.spec-block.active { display: block; }
.spec-block h3 { font-size: 1.6rem; color: var(--text); margin-bottom: 20px; }
.spec-block h4 { font-family: var(--sans); font-size: 1.05rem; font-weight: 500; color: var(--text); margin: 28px 0 12px; }
.spec-block p { margin-bottom: 12px; }
.spec-table { width: 100%; border-collapse: collapse; font-size: 0.88rem; margin: 20px 0; }
.spec-table th {
  font-family: var(--mono); font-size: 0.68rem; letter-spacing: 0.1em;
  text-transform: uppercase; color: var(--text-dim); text-align: left;
  padding: 12px 16px; border-bottom: 1px solid var(--border); background: var(--bg-card);
}
.spec-table td {
  padding: 10px 16px; border-bottom: 1px solid var(--border-subtle);
  color: var(--text-muted); vertical-align: top; font-weight: 300; line-height: 1.5;
}
.spec-table tr td:first-child { color: var(--text); font-weight: 400; font-family: var(--mono); font-size: 0.82rem; }
.spec-table .hl { color: var(--glow); }
.spec-code {
  background: var(--bg-card); border: 1px solid var(--border-subtle); border-radius: 8px;
  padding: 20px 24px; margin: 16px 0 20px; overflow-x: auto;
  font-family: var(--mono); font-size: 0.78rem; line-height: 1.7; color: var(--text-muted);
  white-space: pre;
}
.spec-code .key { color: var(--glow); }
.spec-code .str { color: var(--warm); }
.spec-code .num { color: var(--blue); }
.spec-code .bool { color: var(--red); }
.spec-code .null-val { color: var(--text-dim); }
.spec-formula {
  background: var(--bg-card); border: 1px solid var(--border-subtle); border-radius: 6px;
  padding: 14px 20px; margin: 12px 0 16px;
  font-family: var(--mono); font-size: 0.82rem; color: var(--glow); display: inline-block;
}
.spec-dl { margin: 16px 0; }
.spec-dl dt {
  font-family: var(--mono); font-size: 0.85rem; color: var(--text);
  margin-top: 16px; margin-bottom: 4px;
}
.spec-dl dd { color: var(--text-dim); font-size: 0.92rem; padding-left: 16px; border-left: 2px solid var(--border-subtle); }
.spec-lifecycle {
  background: var(--bg-card); border: 1px solid var(--border-subtle); border-radius: 8px;
  padding: 24px 28px; margin: 16px 0;
  font-family: var(--mono); font-size: 0.85rem; color: var(--text-muted);
  display: flex; flex-wrap: wrap; align-items: center; gap: 8px; justify-content: center;
}
.spec-lifecycle .phase {
  padding: 6px 14px; border-radius: 4px; background: rgba(74,222,128,0.08);
  color: var(--glow); border: 1px solid rgba(74,222,128,0.15);
}
.spec-lifecycle .arrow { color: var(--text-dim); }
.spec-badge {
  display: inline-block; padding: 3px 10px; border-radius: 3px;
  font-family: var(--mono); font-size: 0.68rem; letter-spacing: 0.06em;
}
.spec-badge.elite { background: rgba(74,222,128,0.10); color: var(--glow); }
.spec-badge.draft { background: rgba(255,214,160,0.10); color: var(--warm); }
.spec-version-info {
  display: flex; gap: 16px; align-items: center; margin-top: 8px;
}
.spec-tabs { display: flex; gap: 0; margin: 20px 0 0; border-bottom: 1px solid var(--border-subtle); }
.spec-tab {
  font-family: var(--mono); font-size: 0.72rem; color: var(--text-dim);
  padding: 10px 20px; cursor: pointer; border-bottom: 2px solid transparent;
  transition: all 0.2s; background: none; border-top: none; border-left: none; border-right: none;
}
.spec-tab:hover { color: var(--text-muted); }
.spec-tab.active { color: var(--glow); border-bottom-color: var(--glow); }
.spec-tab-content { display: none; padding-top: 20px; }
.spec-tab-content.active { display: block; }
.spec-supporting-card {
  background: var(--bg-card); border: 1px solid var(--border-subtle); border-radius: 8px;
  padding: 24px 28px; margin-bottom: 20px;
}
.spec-supporting-card h4 {
  font-family: var(--mono); font-size: 0.95rem; color: var(--text); margin: 0 0 6px;
}
.spec-supporting-card .feeds {
  font-family: var(--mono); font-size: 0.68rem; color: var(--glow-dim);
  letter-spacing: 0.04em; margin-bottom: 12px;
}
.spec-supporting-card p { margin-bottom: 8px; }
.spec-supporting-card p:last-child { margin-bottom: 0; }
.spec-relationship-map {
  background: var(--bg-card); border: 1px solid var(--border-subtle); border-radius: 8px;
  padding: 28px 32px; margin: 24px 0; overflow-x: auto;
  font-family: var(--mono); font-size: 0.78rem; line-height: 1.8; white-space: pre;
}
.spec-relationship-map .supporting { color: var(--warm); }
.spec-relationship-map .arrow { color: var(--text-dim); }
.spec-relationship-map .headline { color: var(--glow); }
.spec-relationship-map .connector { color: var(--text-dim); }

/* ── Animations ── */
.fade-in { opacity: 0; transform: translateY(16px); transition: opacity 0.7s ease, transform 0.7s ease; }
.fade-in.visible { opacity: 1; transform: translateY(0); }

/* ── Responsive ── */
@media (max-width: 768px) {
  .container { padding: 0 20px; }
  section { padding: 64px 0; }
  nav { padding: 12px 16px; }
  nav .nav-links { display: none; }

  /* Hero */
  .hero { padding: 80px 0 48px; min-height: auto; }
  .hero-eyebrow { font-size: 0.7rem; margin-bottom: 20px; }
  .hero-sub { font-size: 1.15rem; margin: 20px 0 32px; }
  .hero-cta { gap: 10px; }
  .btn { padding: 12px 20px; font-size: 0.75rem; }

  /* Grids */
  .problem-grid, .metrics-grid, .metrics-grid.two-col, .principles { grid-template-columns: 1fr; }
  .dimension-grid { grid-template-columns: 1fr 1fr; }

  /* Cards */
  .problem-card { padding: 24px; }
  .insight-box { padding: 24px; }
  .insight-box h3 { font-size: 1.5rem; }
  .hierarchy { font-size: 0.7rem; padding: 16px; overflow-x: auto; line-height: 1.8; }
  .metric-card { padding: 28px 20px; }
  .dimension { padding: 18px 12px; }
  .dimension-weight { font-size: 1.8rem; }
  .dimension-name { font-size: 0.78rem; }
  .dimension-desc { font-size: 0.72rem; }

  /* Comparison table */
  .comparison { -webkit-overflow-scrolling: touch; }
  .comparison table { font-size: 0.8rem; min-width: 480px; }
  .comparison th, .comparison td { padding: 10px 12px; }

  /* Architecture */
  .arch-diagram { padding: 20px; }
  .arch-layer { flex-wrap: wrap; gap: 8px; padding: 10px 0; }
  .arch-layer .desc { font-size: 0.78rem; }

  /* Principles */
  .principle { padding: 20px; }
  .principle h3 { font-size: 0.95rem; }
  .principle p { font-size: 0.85rem; }

  /* CTA */
  .cta-section { padding: 80px 0; }
  .cta-actions { flex-direction: column; align-items: center; }

  /* Spec section */
  .spec-block h3 { font-size: 1.3rem; }
  .spec-nav button { font-size: 0.65rem; padding: 8px 10px; }
  .spec-table { font-size: 0.8rem; display: block; overflow-x: auto; -webkit-overflow-scrolling: touch; }
  .spec-table th, .spec-table td { padding: 8px 10px; }
  .spec-code { font-size: 0.68rem; padding: 14px 12px; }
  .spec-formula { font-size: 0.72rem; padding: 10px 14px; }
  .spec-lifecycle { font-size: 0.72rem; gap: 4px; padding: 16px; }
  .spec-lifecycle .phase { padding: 4px 10px; font-size: 0.68rem; }
  .spec-supporting-card { padding: 18px 16px; }
  .spec-supporting-card h4 { font-size: 0.88rem; }
  .spec-supporting-card .feeds { font-size: 0.62rem; }
  .spec-supporting-card p { font-size: 0.88rem; }
  .spec-relationship-map { font-size: 0.58rem; padding: 14px 12px; line-height: 1.6; }
  .spec-tabs { overflow-x: auto; -webkit-overflow-scrolling: touch; }
  .spec-tab { padding: 8px 14px; font-size: 0.65rem; white-space: nowrap; }
  .spec-dl dd { font-size: 0.85rem; }
  .spec-version-info { flex-wrap: wrap; gap: 10px; }
}

@media (max-width: 480px) {
  .container { padding: 0 16px; }
  h1 { font-size: clamp(2.4rem, 10vw, 3.2rem); }
  h2 { font-size: clamp(1.6rem, 5vw, 2rem); }
  .hero { padding: 72px 0 40px; }
  .hero-cta { flex-direction: column; }
  .hero-cta .btn { width: 100%; justify-content: center; }
  .dimension-grid { grid-template-columns: 1fr; }
  .arch-diagram { padding: 16px; }
  .arch-layer .tag { font-size: 0.62rem; }
  .arch-layer .desc { font-size: 0.72rem; }
  .spec-relationship-map { font-size: 0.5rem; padding: 12px 8px; }
  .comparison table { min-width: 420px; }
  .spec-lifecycle { flex-direction: column; align-items: stretch; text-align: center; }
  .spec-lifecycle .arrow { display: none; }
}
</style>
</head>
<body>

<div class="draft-banner">
  <strong>DRAFT PROPOSAL</strong>
  <span>·</span>
  <span>This is a proposal, not a finished product. Read, challenge, and improve it.</span>
  <span>·</span>
  <a href="https://github.com/orgs/aura-metrics/discussions" target="_blank" rel="noopener">Join the discussion →</a>
</div>

<nav>
  <a href="#" class="logo"><span>AURA</span></a>
  <ul class="nav-links">
    <li><a href="#problem">The Problem</a></li>
    <li><a href="#metrics">The 5 Metrics</a></li>
    <li><a href="#specification">Specification</a></li>
    <li><a href="#implementation">Get Involved</a></li>
    <li><a href="#origin">Origin</a></li>
  </ul>
  <a href="https://github.com/aura-metrics/" class="nav-github" target="_blank" rel="noopener">
    <svg viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/></svg>
    GitHub
  </a>
</nav>

<!-- ═══════════ HERO ═══════════ -->
<section class="hero">
  <div class="container">
    <div class="hero-eyebrow">DORA for pipelines. AURA for agents.</div>
    <h1>
      See what your agents<br>
      <span class="glow">actually deliver</span>
    </h1>
    <p class="hero-sub">
      DORA for pipelines. AURA for agents.<br>
      Five metrics. Built on OpenTelemetry.
    </p>
    <div class="hero-cta">
      <a href="#metrics" class="btn btn-primary">The five metrics ↓</a>
      <a href="https://github.com/orgs/aura-metrics/discussions" class="btn btn-ghost" target="_blank" rel="noopener">Join the discussion →</a>
    </div>
  </div>
</section>

<!-- ═══════════ PROBLEM ═══════════ -->
<section id="problem">
  <div class="container">
    <span class="label">The problem</span>
    <h2>Your agents are black boxes</h2>
    <p>DORA gave software delivery four clear metrics. AI agents have nothing. Every team invents their own, making it impossible to benchmark or improve.</p>
    <div class="problem-grid fade-in">
      <div class="problem-card">
        <div class="num">01</div>
        <h3>No standard metrics</h3>
        <p>Is the agent delivering what was asked? How would you know? Every team tracks something different.</p>
      </div>
      <div class="problem-card">
        <div class="num">02</div>
        <h3>Task ≠ Value</h3>
        <p>Measuring tool calls is like measuring commits instead of deployments. Activity isn't delivery.</p>
      </div>
      <div class="problem-card">
        <div class="num">03</div>
        <h3>No quality gradient</h3>
        <p>Binary pass/fail doesn't capture reality. Two agents can "complete" a feature — one nails it, the other barely passes.</p>
      </div>
      <div class="problem-card">
        <div class="num">04</div>
        <h3>Recovery is invisible</h3>
        <p>When an agent fails mid-task, does it self-correct or spiral in a loop burning tokens? You can't tell until you check the bill.</p>
      </div>
    </div>
  </div>
</section>

<!-- ═══════════ INSIGHT ═══════════ -->
<section id="insight">
  <div class="container">
    <span class="label">Key insight</span>
    <h2>Measure deliverables, not tasks</h2>
    <p>DORA measures <strong style="color:var(--text)">deployments</strong>, not commits. AURA applies the same principle: measure the unit of value delivered against a specification.</p>
    <div class="insight-box fade-in">
      <h3>A task is a commit.<br>A deliverable is a deployment.</h3>
      <p>An agent might complete 50 tasks in pursuit of one thing a user cares about. That one thing, verified against a spec, is what AURA measures.</p>
      <div class="hierarchy">
        <span class="hl">Deliverable</span> <span class="dim">← unit of measurement for AURA</span><br>
        ├── <span class="hl">Spec</span> <span class="dim">← what was requested (acceptance criteria)</span><br>
        ├── Plan <span class="dim">← how the agent approaches it</span><br>
        ├── Tasks <span class="dim">← individual steps</span><br>
        │&nbsp;&nbsp;&nbsp;├── LLM calls<br>
        │&nbsp;&nbsp;&nbsp;├── Tool calls<br>
        │&nbsp;&nbsp;&nbsp;└── Reasoning steps<br>
        └── <span class="hl">Outcome</span><br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└── <span class="hl">Delivery Completeness</span> <span class="dim">← how well did it match?</span>
      </div>
    </div>
  </div>
</section>

<!-- ═══════════ PHILOSOPHY ═══════════ -->
<section>
  <div class="container">
    <span class="label">Philosophy</span>
    <h2>What AURA believes</h2>
    <div class="principles fade-in">
      <div class="principle"><div class="principle-num">01</div><h3>Measure deliverables, not tasks</h3><p>Tool calls are commits. Deliverables are deployments. Measure value.</p></div>
      <div class="principle"><div class="principle-num">02</div><h3>Speed, stability, and quality correlate</h3><p>The best agents are fast, reliable, and accurate. Optimizing one at the expense of others hides deeper problems.</p></div>
      <div class="principle"><div class="principle-num">03</div><h3>The spec is the source of truth</h3><p>Without a spec, you can't measure quality. AURA makes specs explicit.</p></div>
      <div class="principle"><div class="principle-num">04</div><h3>Metrics drive conversations</h3><p>Not leaderboards. Not punishments. Conversations about where to improve.</p></div>
      <div class="principle"><div class="principle-num">05</div><h3>Build on existing standards</h3><p>OTel GenAI semantic conventions. Your infrastructure already works.</p></div>
      <div class="principle"><div class="principle-num">06</div><h3>Start simple, go deep</h3><p>Five headline metrics tell the story. Supporting metrics tell you why.</p></div>
    </div>
  </div>
</section>

<!-- ═══════════ WHY NOT DORA ═══════════ -->
<section>
  <div class="container">
    <span class="label">A natural question</span>
    <h2>Why not just use DORA?</h2>
    <p>DORA is excellent — if you're shipping software, you should be tracking it. AURA doesn't replace DORA. It fills a gap DORA was never designed to cover.</p>
    <p style="margin-top:20px;">DORA measures how well your <strong style="color:var(--text)">pipeline</strong> delivers code to production. It assumes a human wrote the code, a CI system tested it, and a deployment shipped it. AI agents don't have pipelines. They receive a request, reason, call tools, and produce output. The failure modes aren't broken builds — they're hallucinations, spec mismatches, and infinite loops. The quality question isn't "did it deploy safely?" but "did it do what was asked?"</p>
    <p style="margin-top:20px;">If your agents write code that flows through a DORA-measured pipeline, the two complement each other perfectly: <strong style="color:var(--text)">DORA measures the pipeline. AURA measures the agent.</strong></p>
  </div>
</section>

<!-- ═══════════ METRICS ═══════════ -->
<section id="metrics">
  <div class="container">
    <div class="metrics-header">
      <span class="label">The five metrics</span>
      <h2>Throughput · Stability · Quality</h2>
      <p>Like DORA, AURA captures the tension between speed and stability. Unlike DORA, it adds a quality dimension unique to AI.</p>
    </div>

    <div class="metrics-grid fade-in" style="margin-bottom:1px;">
      <div class="metric-card">
        <div class="metric-number">01 · Throughput</div>
        <div class="metric-name">Feature Throughput</div>

        <div class="metric-desc">Deliverables accepted per time period. Measures productivity at the level humans care about.</div>
        <div class="tiers">
          <div class="tier elite"><span class="tier-label">Elite</span><span class="tier-value">&gt;20 /day</span></div>
          <div class="tier"><span class="tier-label">High</span><span class="tier-value">5–20 /day</span></div>
          <div class="tier"><span class="tier-label">Medium</span><span class="tier-value">1–5 /day</span></div>
          <div class="tier"><span class="tier-label">Low</span><span class="tier-value">&lt;1 /day</span></div>
        </div>
      </div>
      <div class="metric-card">
        <div class="metric-number">02 · Throughput</div>
        <div class="metric-name">Resolution Latency</div>

        <div class="metric-desc">Spec received to verified deliverable. Includes planning, execution, validation, and rework.</div>
        <div class="tiers">
          <div class="tier elite"><span class="tier-label">Elite</span><span class="tier-value">p50 &lt; 1m</span></div>
          <div class="tier"><span class="tier-label">High</span><span class="tier-value">p50 &lt; 5m</span></div>
          <div class="tier"><span class="tier-label">Medium</span><span class="tier-value">p50 &lt; 30m</span></div>
          <div class="tier"><span class="tier-label">Low</span><span class="tier-value">p50 &gt; 30m</span></div>
        </div>
      </div>
      <div class="metric-card">
        <div class="metric-number">03 · Stability</div>
        <div class="metric-name">Deliverable Failure Rate</div>

        <div class="metric-desc">Percentage of deliverables that fail spec, require human takeover, or are abandoned.</div>
        <div class="tiers">
          <div class="tier elite"><span class="tier-label">Elite</span><span class="tier-value">&lt;5%</span></div>
          <div class="tier"><span class="tier-label">High</span><span class="tier-value">5–15%</span></div>
          <div class="tier"><span class="tier-label">Medium</span><span class="tier-value">15–30%</span></div>
          <div class="tier"><span class="tier-label">Low</span><span class="tier-value">&gt;30%</span></div>
        </div>
      </div>
    </div>

    <div class="metrics-grid two-col fade-in">
      <div class="metric-card">
        <div class="metric-number">04 · Stability</div>
        <div class="metric-name">Recovery Efficiency</div>

        <div class="metric-desc">When things fail mid-delivery, how efficiently does the agent self-correct? Ratio of recovery overhead to total time.</div>
        <div class="tiers">
          <div class="tier elite"><span class="tier-label">Elite</span><span class="tier-value">&lt;10% overhead</span></div>
          <div class="tier"><span class="tier-label">High</span><span class="tier-value">10–25%</span></div>
          <div class="tier"><span class="tier-label">Medium</span><span class="tier-value">25–50%</span></div>
          <div class="tier"><span class="tier-label">Low</span><span class="tier-value">&gt;50%</span></div>
        </div>
      </div>
      <div class="metric-card">
        <div class="metric-number" style="color:var(--glow);">05 · Quality — Unique to AURA</div>
        <div class="metric-name">Delivery Completeness</div>

        <div class="metric-desc">How completely did the agent deliver what was asked? A percentage score from 0–100% across functional, correctness, and constraint dimensions.</div>
        <div class="tiers">
          <div class="tier elite"><span class="tier-label">Elite</span><span class="tier-value">&gt;95%</span></div>
          <div class="tier"><span class="tier-label">High</span><span class="tier-value">80–95%</span></div>
          <div class="tier"><span class="tier-label">Medium</span><span class="tier-value">60–80%</span></div>
          <div class="tier"><span class="tier-label">Low</span><span class="tier-value">&lt;60%</span></div>
        </div>
      </div>
    </div>

    <div style="margin-top: 48px;" class="fade-in">
      <h3 style="text-align:center; margin-bottom:8px;">Completeness Dimensions</h3>
      <p style="text-align:center; margin:0 auto;">Four weighted dimensions that capture how completely and accurately the agent delivered.</p>
      <div class="dimension-grid">
        <div class="dimension">
          <div class="dimension-weight">40%</div>
          <div class="dimension-name">Functional Completeness</div>
          <div class="dimension-desc">Did it do everything<br>the spec asked?</div>
        </div>
        <div class="dimension">
          <div class="dimension-weight">30%</div>
          <div class="dimension-name">Correctness</div>
          <div class="dimension-desc">Is the output factually<br>and logically right?</div>
        </div>
        <div class="dimension">
          <div class="dimension-weight">20%</div>
          <div class="dimension-name">Constraint Adherence</div>
          <div class="dimension-desc">Did it respect boundaries,<br>formats, and limits?</div>
        </div>
        <div class="dimension">
          <div class="dimension-weight">10%</div>
          <div class="dimension-name">Iteration Count</div>
          <div class="dimension-desc">How many attempts<br>to get it right?</div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ═══════════ COMPARISON ═══════════ -->
<section>
  <div class="container">
    <span class="label">Side by side</span>
    <h2>DORA → AURA</h2>
    <p>Same structure. Different domain. One new dimension.</p>
    <div class="comparison fade-in">
      <table>
        <thead><tr><th>Aspect</th><th>DORA</th><th>AURA</th></tr></thead>
        <tbody>
          <tr><td>Domain</td><td>Software delivery</td><td class="glow-cell">AI agent performance</td></tr>
          <tr><td>Unit</td><td>Deployment</td><td class="glow-cell">Deliverable (against spec)</td></tr>
          <tr><td>Throughput 1</td><td>Deployment Frequency</td><td class="glow-cell">Feature Throughput</td></tr>
          <tr><td>Throughput 2</td><td>Lead Time</td><td class="glow-cell">Resolution Latency</td></tr>
          <tr><td>Stability 1</td><td>Change Failure Rate</td><td class="glow-cell">Deliverable Failure Rate</td></tr>
          <tr><td>Stability 2</td><td>MTTR</td><td class="glow-cell">Recovery Efficiency</td></tr>
          <tr><td>Quality</td><td style="color:var(--text-dim)">—</td><td class="glow-cell">Delivery Completeness</td></tr>
          <tr><td>Data source</td><td>CI/CD pipelines</td><td class="glow-cell">OpenTelemetry traces</td></tr>
        </tbody>
      </table>
    </div>
  </div>
</section>

<!-- ═══════════ SPECIFICATION ═══════════ -->
<section id="specification" class="spec-section">
  <div class="container">
    <span class="label">Specification</span>
    <h2>AURA Specification <span style="font-family:var(--mono);font-size:0.9rem;color:var(--glow-dim);">v0.1.0</span></h2>
    <div class="spec-version-info">
      <span class="spec-badge draft">DRAFT</span>
      <span style="font-family:var(--mono);font-size:0.72rem;color:var(--text-dim);">MIT</span>
      <a href="https://github.com/aura-metrics/aura-metrics-specification" style="font-family:var(--mono);font-size:0.72rem;color:var(--glow-dim);text-decoration:none;">GitHub →</a>
    </div>
    <p style="margin-top:20px;">AURA is a metrics framework that measures the reliability and quality of AI agent output. Like DORA measures software delivery performance through four key metrics, AURA measures agent performance through five: Feature Throughput, Resolution Latency, Deliverable Failure Rate, Recovery Efficiency, and Delivery Completeness.</p>

    <div class="spec-nav">
      <button class="active" onclick="showSpec(this,'spec-terminology')">Terminology</button>
      <button onclick="showSpec(this,'spec-metrics')">Metrics</button>
      <button onclick="showSpec(this,'spec-lifecycle')">Lifecycle</button>
      <button onclick="showSpec(this,'spec-failures')">Failures</button>
      <button onclick="showSpec(this,'spec-data-model')">Data Model</button>
      <button onclick="showSpec(this,'spec-otel')">OpenTelemetry</button>
      <button onclick="showSpec(this,'spec-supporting')">Supporting Metrics</button>
      <button onclick="showSpec(this,'spec-compatibility')">Compatibility</button>
      <button onclick="showSpec(this,'spec-tiers')">Tiers</button>
    </div>

    <!-- ── Terminology ── -->
    <div id="spec-terminology" class="spec-block active fade-in">
      <h3>Terminology</h3>
      <dl class="spec-dl">
        <dt>Deliverable</dt>
        <dd>A unit of agent work verified against a specification. One deliverable = one measurable outcome. Examples: a feature implementation, a bug fix, a refactoring task.</dd>
        <dt>Spec</dt>
        <dd>The acceptance criteria for a deliverable. Can come from any source — an OpenSpec change folder, a Jira ticket, a markdown file, a plain text prompt. The spec defines what "done" means.</dd>
        <dt>Phase</dt>
        <dd>A stage in the deliverable lifecycle. The canonical phases are: <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">propose</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">specs</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">design</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">tasks</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">apply</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">verify</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">archive</code>. Not all phases are required for every deliverable.</dd>
        <dt>Delivery Completeness</dt>
        <dd>How completely a deliverable met its spec, expressed as a percentage (0–100%). Captures quality beyond binary pass/fail — a deliverable can be accepted but still partially complete.</dd>
        <dt>Recovery</dt>
        <dd>A rework cycle triggered by a failure during execution. When verification fails and the agent retries, that retry is a recovery attempt.</dd>
      </dl>
    </div>

    <!-- ── Metrics ── -->
    <div id="spec-metrics" class="spec-block fade-in">
      <h3>The Five Metrics</h3>

      <h4>2.1 Feature Throughput</h4>
      <p>The number of deliverables accepted per unit time.</p>
      <div class="spec-formula">count(deliverables where status = "accepted") / time_period</div>
      <table class="spec-table">
        <thead><tr><th>Tier</th><th>Threshold</th></tr></thead>
        <tbody>
          <tr><td class="hl">Elite</td><td>≥3/day</td></tr>
          <tr><td>High</td><td>≥1/day</td></tr>
          <tr><td>Medium</td><td>≥1/week</td></tr>
          <tr><td>Low</td><td>&lt;1/week</td></tr>
        </tbody>
      </table>

      <h4>2.2 Resolution Latency</h4>
      <p>Wall-clock time from spec received to deliverable accepted. Includes planning, execution, and verification.</p>
      <div class="spec-formula">accepted_at - started_at</div>
      <table class="spec-table">
        <thead><tr><th>Tier</th><th>Threshold</th></tr></thead>
        <tbody>
          <tr><td class="hl">Elite</td><td>&lt;1 hour (3,600s)</td></tr>
          <tr><td>High</td><td>&lt;4 hours (14,400s)</td></tr>
          <tr><td>Medium</td><td>&lt;1 day (86,400s)</td></tr>
          <tr><td>Low</td><td>≥1 day</td></tr>
        </tbody>
      </table>
      <p>Includes human review time. To isolate agent time, subtract human wait phases from the total.</p>

      <h4>2.3 Deliverable Failure Rate</h4>
      <p>Percentage of deliverables that fail spec conformance.</p>
      <div class="spec-formula">count(failed) / count(deliverables) × 100</div>
      <table class="spec-table">
        <thead><tr><th>Tier</th><th>Threshold</th></tr></thead>
        <tbody>
          <tr><td class="hl">Elite</td><td>&lt;5%</td></tr>
          <tr><td>High</td><td>&lt;10%</td></tr>
          <tr><td>Medium</td><td>&lt;15%</td></tr>
          <tr><td>Low</td><td>≥15%</td></tr>
        </tbody>
      </table>
      <p>A deliverable that required recovery but eventually passed is NOT failed. Only deliverables abandoned or accepted below the conformance threshold are failed.</p>

      <h4>2.4 Recovery Efficiency</h4>
      <p>The proportion of total effort spent on rework and retries.</p>
      <div class="spec-formula">recovery_time / total_time × 100</div>
      <table class="spec-table">
        <thead><tr><th>Tier</th><th>Threshold</th></tr></thead>
        <tbody>
          <tr><td class="hl">Elite</td><td>&lt;5%</td></tr>
          <tr><td>High</td><td>&lt;10%</td></tr>
          <tr><td>Medium</td><td>&lt;20%</td></tr>
          <tr><td>Low</td><td>≥20%</td></tr>
        </tbody>
      </table>

      <h4>2.5 Delivery Completeness</h4>
      <p>A weighted quality score measuring how well an accepted deliverable matches its spec.</p>
      <div class="spec-formula">(0.4 × functional) + (0.3 × correctness) + (0.2 × constraints) + (0.1 × iteration_penalty)</div>
      <table class="spec-table">
        <thead><tr><th>Tier</th><th>Threshold</th></tr></thead>
        <tbody>
          <tr><td class="hl">Elite</td><td>≥95%</td></tr>
          <tr><td>High</td><td>≥85%</td></tr>
          <tr><td>Medium</td><td>≥70%</td></tr>
          <tr><td>Low</td><td>&lt;0.70</td></tr>
        </tbody>
      </table>

      <h4>2.5.1 Completeness Dimensions</h4>
      <table class="spec-table">
        <thead><tr><th>Dimension</th><th>Weight</th><th>Calculation</th></tr></thead>
        <tbody>
          <tr><td>Functional Completeness</td><td>0.4</td><td style="color:var(--text-muted)">completed_requirements / total_requirements</td></tr>
          <tr><td>Correctness</td><td>0.3</td><td style="color:var(--text-muted)">Binary or scored by validation</td></tr>
          <tr><td>Constraint Adherence</td><td>0.2</td><td style="color:var(--text-muted)">1.0 - (0.1 × constraint_violations), floor 0.0</td></tr>
          <tr><td>Iteration Penalty</td><td>0.1</td><td style="color:var(--text-muted)">max(0, 1.0 - (0.15 × (iterations - 1)))</td></tr>
        </tbody>
      </table>
    </div>

    <!-- ── Lifecycle ── -->
    <div id="spec-lifecycle" class="spec-block fade-in">
      <h3>Deliverable Lifecycle</h3>
      <p>A deliverable progresses through phases. Not all phases are required — a minimal deliverable has: start → apply → archive. Phases can repeat (apply → verify → apply → verify → archive).</p>
      <div class="spec-lifecycle">
        <span class="phase">propose</span><span class="arrow">→</span>
        <span class="phase">specs</span><span class="arrow">→</span>
        <span class="phase">design</span><span class="arrow">→</span>
        <span class="phase">tasks</span><span class="arrow">→</span>
        <span class="phase">apply</span><span class="arrow">→</span>
        <span class="phase">verify</span><span class="arrow">→</span>
        <span class="phase">archive</span>
      </div>

      <h4>Phase Definitions</h4>
      <table class="spec-table">
        <thead><tr><th>Phase</th><th>Description</th><th>Data Captured</th></tr></thead>
        <tbody>
          <tr><td>propose</td><td style="color:var(--text-muted)">Deliverable is identified and scoped</td><td style="color:var(--text-dim)">Start timestamp, deliverable ID, description</td></tr>
          <tr><td>specs</td><td style="color:var(--text-muted)">Requirements and acceptance criteria defined</td><td style="color:var(--text-dim)">Start/end timestamps, requirements count</td></tr>
          <tr><td>design</td><td style="color:var(--text-muted)">Solution approach is planned</td><td style="color:var(--text-dim)">Start/end timestamps, design artifacts</td></tr>
          <tr><td>tasks</td><td style="color:var(--text-muted)">Work is broken into discrete tasks</td><td style="color:var(--text-dim)">Start/end timestamps, task count</td></tr>
          <tr><td>apply</td><td style="color:var(--text-muted)">Agent executes the work</td><td style="color:var(--text-dim)">Start/end timestamps, tool calls, files changed</td></tr>
          <tr><td>verify</td><td style="color:var(--text-muted)">Output is validated against the spec</td><td style="color:var(--text-dim)">Start/end timestamps, test results, conformance</td></tr>
          <tr><td>archive</td><td style="color:var(--text-muted)">Deliverable is finalized and recorded</td><td style="color:var(--text-dim)">End timestamp, final metrics</td></tr>
        </tbody>
      </table>

      <h4>Deliverable States</h4>
      <table class="spec-table">
        <thead><tr><th>State</th><th>Description</th></tr></thead>
        <tbody>
          <tr><td>planning</td><td style="color:var(--text-muted)">In propose, specs, design, or tasks phase</td></tr>
          <tr><td>executing</td><td style="color:var(--text-muted)">In apply phase</td></tr>
          <tr><td>verifying</td><td style="color:var(--text-muted)">In verify phase</td></tr>
          <tr><td>completed</td><td style="color:var(--text-muted)">Archived successfully</td></tr>
          <tr><td>failed</td><td style="color:var(--text-muted)">Abandoned or below conformance threshold</td></tr>
        </tbody>
      </table>
    </div>

    <!-- ── Failures ── -->
    <div id="spec-failures" class="spec-block fade-in">
      <h3>Failure Taxonomy</h3>
      <p>When a deliverable fails, it should be classified by failure type:</p>
      <table class="spec-table">
        <thead><tr><th>Failure Type</th><th>Description</th></tr></thead>
        <tbody>
          <tr><td>spec_misunderstanding</td><td style="color:var(--text-muted)">Agent misinterpreted requirements</td></tr>
          <tr><td>hallucination</td><td style="color:var(--text-muted)">Agent produced fabricated output</td></tr>
          <tr><td>infinite_loop</td><td style="color:var(--text-muted)">Agent got stuck in a retry cycle</td></tr>
          <tr><td>tool_failure</td><td style="color:var(--text-muted)">External tool returned an error the agent couldn't recover from</td></tr>
          <tr><td>constraint_violation</td><td style="color:var(--text-muted)">Output exceeded specified boundaries</td></tr>
          <tr><td>incomplete</td><td style="color:var(--text-muted)">Agent stopped before finishing all requirements</td></tr>
          <tr><td>regression</td><td style="color:var(--text-muted)">Agent's fix broke something that previously worked</td></tr>
        </tbody>
      </table>
    </div>

    <!-- ── Data Model ── -->
    <div id="spec-data-model" class="spec-block fade-in">
      <h3>Data Model</h3>
      <p>AURA defines three JSON Schema documents (JSON Schema draft 2020-12).</p>

      <div class="spec-tabs">
        <button class="spec-tab active" onclick="switchTab(event, 'tab-metrics-output')">Metrics Output</button>
        <button class="spec-tab" onclick="switchTab(event, 'tab-deliverable-state')">Deliverable State</button>
        <button class="spec-tab" onclick="switchTab(event, 'tab-aura-event')">AURA Event</button>
      </div>

      <div id="tab-metrics-output" class="spec-tab-content active">
        <p>The final record emitted when a deliverable is completed or failed. This is the primary AURA output format.</p>
        <div class="spec-code">{
  <span class="key">"schema_version"</span>: <span class="str">"0.1.0"</span>,
  <span class="key">"change_id"</span>: <span class="str">"add-dark-mode"</span>,
  <span class="key">"started_at"</span>: <span class="str">"2026-02-26T10:00:00Z"</span>,
  <span class="key">"completed_at"</span>: <span class="str">"2026-02-26T10:45:00Z"</span>,
  <span class="key">"status"</span>: <span class="str">"completed"</span>,
  <span class="key">"description"</span>: <span class="str">"Add dark mode toggle to settings page"</span>,
  <span class="key">"metrics"</span>: {
    <span class="key">"resolution_latency_seconds"</span>: <span class="num">2700</span>,
    <span class="key">"phase_durations"</span>: {
      <span class="key">"propose"</span>: <span class="num">60</span>, <span class="key">"specs"</span>: <span class="num">120</span>, <span class="key">"design"</span>: <span class="num">180</span>,
      <span class="key">"tasks"</span>: <span class="num">120</span>, <span class="key">"apply"</span>: <span class="num">1800</span>, <span class="key">"verify"</span>: <span class="num">300</span>
    },
    <span class="key">"tool_calls"</span>: { <span class="key">"file_edit"</span>: <span class="num">24</span>, <span class="key">"bash"</span>: <span class="num">15</span>, <span class="key">"total"</span>: <span class="num">87</span> },
    <span class="key">"apply_iterations"</span>: <span class="num">2</span>,
    <span class="key">"recovery_attempts"</span>: <span class="num">1</span>,
    <span class="key">"tasks_completed"</span>: <span class="num">12</span>,
    <span class="key">"tasks_total"</span>: <span class="num">12</span>,
    <span class="key">"conformance"</span>: {
      <span class="key">"functional"</span>: <span class="num">1.0</span>,
      <span class="key">"correctness"</span>: <span class="num">0.95</span>,
      <span class="key">"constraints"</span>: <span class="num">1.0</span>,
      <span class="key">"iteration_penalty"</span>: <span class="num">0.85</span>,
      <span class="key">"overall"</span>: <span class="num">0.97</span>
    },
    <span class="key">"deliverable_failed"</span>: <span class="bool">false</span>,
    <span class="key">"failure_type"</span>: <span class="null-val">null</span>
  },
  <span class="key">"spec_source"</span>: {
    <span class="key">"framework"</span>: <span class="str">"openspec"</span>,
    <span class="key">"spec_id"</span>: <span class="str">"changes/add-dark-mode"</span>,
    <span class="key">"requirements_count"</span>: <span class="num">8</span>
  },
  <span class="key">"agent"</span>: {
    <span class="key">"name"</span>: <span class="str">"claude-code"</span>,
    <span class="key">"model"</span>: <span class="str">"claude-sonnet-4-20250514"</span>,
    <span class="key">"framework"</span>: <span class="str">"claude-code"</span>
  },
  <span class="key">"sessions"</span>: [<span class="str">"session-d4e5f6"</span>]
}</div>
        <p>Required fields: <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">schema_version</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">change_id</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">started_at</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">completed_at</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">status</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">metrics</code></p>
      </div>

      <div id="tab-deliverable-state" class="spec-tab-content">
        <p>Tracks the current state of an in-progress deliverable. Updated as the agent progresses through phases.</p>
        <div class="spec-code">{
  <span class="key">"change_id"</span>: <span class="str">"add-search-feature"</span>,
  <span class="key">"status"</span>: <span class="str">"executing"</span>,
  <span class="key">"started_at"</span>: <span class="str">"2026-02-26T09:00:00Z"</span>,
  <span class="key">"updated_at"</span>: <span class="str">"2026-02-26T09:35:00Z"</span>,
  <span class="key">"complexity"</span>: <span class="str">"moderate"</span>,
  <span class="key">"description"</span>: <span class="str">"Add full-text search to the product catalog"</span>,
  <span class="key">"spec_source"</span>: {
    <span class="key">"framework"</span>: <span class="str">"openspec"</span>,
    <span class="key">"spec_id"</span>: <span class="str">"changes/add-search-feature"</span>,
    <span class="key">"requirements_count"</span>: <span class="num">6</span>
  },
  <span class="key">"phases"</span>: {
    <span class="key">"propose"</span>: { <span class="key">"started_at"</span>: <span class="str">"..."</span>, <span class="key">"completed_at"</span>: <span class="str">"..."</span> },
    <span class="key">"apply"</span>:   { <span class="key">"started_at"</span>: <span class="str">"..."</span>, <span class="key">"completed_at"</span>: <span class="null-val">null</span> }
  },
  <span class="key">"current_phase"</span>: <span class="str">"apply"</span>,
  <span class="key">"tasks_total"</span>: <span class="num">8</span>,
  <span class="key">"tasks_completed"</span>: <span class="num">4</span>,
  <span class="key">"tool_calls"</span>: { <span class="key">"file_edit"</span>: <span class="num">8</span>, <span class="key">"file_read"</span>: <span class="num">12</span>, <span class="key">"bash"</span>: <span class="num">3</span> },
  <span class="key">"tool_calls_total"</span>: <span class="num">28</span>,
  <span class="key">"recovery_attempts"</span>: <span class="num">0</span>,
  <span class="key">"apply_iterations"</span>: <span class="num">1</span>
}</div>
        <p>Required fields: <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">change_id</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">status</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">started_at</code></p>
      </div>

      <div id="tab-aura-event" class="spec-tab-content">
        <p>Lightweight event records for streaming and real-time collection. Emitted at phase transitions and significant moments during execution.</p>
        <div class="spec-code">{
  <span class="key">"event_type"</span>: <span class="str">"phase_start"</span>,
  <span class="key">"timestamp"</span>: <span class="str">"2026-02-26T10:05:00Z"</span>,
  <span class="key">"change_id"</span>: <span class="str">"add-dark-mode"</span>,
  <span class="key">"phase"</span>: <span class="str">"apply"</span>,
  <span class="key">"data"</span>: { <span class="key">"task_index"</span>: <span class="num">3</span> }
}</div>
        <p>Event types: <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">phase_start</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">phase_end</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">tool_call</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">recovery</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">deliverable_start</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">deliverable_end</code></p>
        <p>Required fields: <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">event_type</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">timestamp</code>, <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">change_id</code></p>
      </div>

      <h4>Schema Validation</h4>
      <div class="spec-code"><span style="color:var(--text-dim)"># Node</span>
npx ajv validate -s schemas/latest/metrics-output.schema.json -d my-output.json

<span style="color:var(--text-dim)"># Python</span>
python -m jsonschema -i my-output.json schemas/latest/metrics-output.schema.json</div>
    </div>

    <!-- ── OpenTelemetry ── -->
    <div id="spec-otel" class="spec-block fade-in">
      <h3>OpenTelemetry Integration</h3>
      <p>AURA extends OTel GenAI semantic conventions with the <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">aura.*</code> namespace. All attributes use this prefix to avoid collision with existing OTel conventions.</p>

      <h4>Span Hierarchy</h4>
      <div class="spec-code">aura.deliverable <span style="color:var(--text-dim)">(root span)</span>
├── aura.deliverable.plan
├── aura.deliverable.execute
│   ├── aura.task
│   │   ├── <span style="color:var(--blue)">gen_ai.chat</span> <span style="color:var(--text-dim)">(OTel GenAI standard)</span>
│   │   └── aura.tool.call
│   └── aura.recovery.attempt
├── aura.deliverable.validate
│   ├── aura.completeness.functional
│   ├── aura.completeness.correctness
│   └── aura.completeness.constraints
└── aura.deliverable.accept</div>

      <h4>Semantic Attributes</h4>
      <table class="spec-table">
        <thead><tr><th>Attribute</th><th>Type</th><th>Description</th></tr></thead>
        <tbody>
          <tr><td>aura.deliverable.id</td><td style="color:var(--text-muted)">string</td><td style="color:var(--text-dim)">Unique deliverable identifier</td></tr>
          <tr><td>aura.deliverable.type</td><td style="color:var(--text-muted)">string</td><td style="color:var(--text-dim)">feature, bugfix, refactor, chore</td></tr>
          <tr><td>aura.deliverable.status</td><td style="color:var(--text-muted)">string</td><td style="color:var(--text-dim)">planning, executing, verifying, completed, failed</td></tr>
          <tr><td>aura.deliverable.complexity</td><td style="color:var(--text-muted)">string</td><td style="color:var(--text-dim)">trivial, simple, moderate, complex</td></tr>
          <tr><td>aura.spec.framework</td><td style="color:var(--text-muted)">string</td><td style="color:var(--text-dim)">openspec, jira, github-issue, markdown, prompt</td></tr>
          <tr><td>aura.spec.id</td><td style="color:var(--text-muted)">string</td><td style="color:var(--text-dim)">Spec identifier</td></tr>
          <tr><td>aura.spec.requirements_count</td><td style="color:var(--text-muted)">int</td><td style="color:var(--text-dim)">Number of requirements extracted</td></tr>
          <tr><td>aura.phase.name</td><td style="color:var(--text-muted)">string</td><td style="color:var(--text-dim)">Current phase name</td></tr>
          <tr><td>aura.phase.iteration</td><td style="color:var(--text-muted)">int</td><td style="color:var(--text-dim)">Phase iteration count</td></tr>
          <tr><td>aura.completeness.functional</td><td style="color:var(--text-muted)">double</td><td style="color:var(--text-dim)">Functional completeness (0–100%)</td></tr>
          <tr><td>aura.completeness.correctness</td><td style="color:var(--text-muted)">double</td><td style="color:var(--text-dim)">Correctness score (0–100%)</td></tr>
          <tr><td>aura.completeness.constraints</td><td style="color:var(--text-muted)">double</td><td style="color:var(--text-dim)">Constraint adherence (0–100%)</td></tr>
          <tr><td>aura.completeness.iteration_penalty</td><td style="color:var(--text-muted)">double</td><td style="color:var(--text-dim)">Iteration penalty (0–100%)</td></tr>
          <tr><td>aura.completeness.overall</td><td style="color:var(--text-muted)">double</td><td style="color:var(--text-dim)">Weighted overall score (0–100%)</td></tr>
          <tr><td>aura.failure.type</td><td style="color:var(--text-muted)">string</td><td style="color:var(--text-dim)">Failure classification</td></tr>
          <tr><td>aura.recovery.attempt</td><td style="color:var(--text-muted)">int</td><td style="color:var(--text-dim)">Current recovery attempt number</td></tr>
          <tr><td>aura.recovery.total</td><td style="color:var(--text-muted)">int</td><td style="color:var(--text-dim)">Total recovery attempts</td></tr>
          <tr><td>aura.agent.name</td><td style="color:var(--text-muted)">string</td><td style="color:var(--text-dim)">Agent identifier</td></tr>
          <tr><td>aura.agent.model</td><td style="color:var(--text-muted)">string</td><td style="color:var(--text-dim)">Model used</td></tr>
          <tr><td>aura.agent.framework</td><td style="color:var(--text-muted)">string</td><td style="color:var(--text-dim)">Agent framework</td></tr>
        </tbody>
      </table>

      <h4>Metric Instruments</h4>
      <table class="spec-table">
        <thead><tr><th>Instrument</th><th>Type</th><th>Unit</th><th>Description</th></tr></thead>
        <tbody>
          <tr><td>aura.deliverables.count</td><td style="color:var(--text-muted)">Counter</td><td style="color:var(--text-dim)">{deliverable}</td><td style="color:var(--text-dim)">Total deliverables processed</td></tr>
          <tr><td>aura.deliverables.accepted</td><td style="color:var(--text-muted)">Counter</td><td style="color:var(--text-dim)">{deliverable}</td><td style="color:var(--text-dim)">Deliverables accepted</td></tr>
          <tr><td>aura.deliverables.failed</td><td style="color:var(--text-muted)">Counter</td><td style="color:var(--text-dim)">{deliverable}</td><td style="color:var(--text-dim)">Deliverables failed</td></tr>
          <tr><td>aura.resolution_latency</td><td style="color:var(--text-muted)">Histogram</td><td style="color:var(--text-dim)">s</td><td style="color:var(--text-dim)">Resolution latency distribution</td></tr>
          <tr><td>aura.completeness.score</td><td style="color:var(--text-muted)">Histogram</td><td style="color:var(--text-dim)">1</td><td style="color:var(--text-dim)">Conformance score distribution</td></tr>
          <tr><td>aura.recovery.attempts</td><td style="color:var(--text-muted)">Histogram</td><td style="color:var(--text-dim)">{attempt}</td><td style="color:var(--text-dim)">Recovery attempts per deliverable</td></tr>
          <tr><td>aura.tool_calls.count</td><td style="color:var(--text-muted)">Counter</td><td style="color:var(--text-dim)">{call}</td><td style="color:var(--text-dim)">Total tool calls</td></tr>
        </tbody>
      </table>
    </div>

    <!-- ── Compatibility ── -->
    <div id="spec-compatibility" class="spec-block fade-in">
      <h3>Spec Framework Compatibility</h3>
      <p>AURA is spec-framework agnostic. Any system that defines acceptance criteria for agent work can be an AURA spec source.</p>
      <table class="spec-table">
        <thead><tr><th>Source</th><th>Spec =</th><th>Requirements =</th><th>Deliverable Boundary</th></tr></thead>
        <tbody>
          <tr><td>OpenSpec</td><td style="color:var(--text-muted)">Change folder</td><td style="color:var(--text-muted)">Delta spec requirements</td><td style="color:var(--text-dim)">propose → archive</td></tr>
          <tr><td>Jira</td><td style="color:var(--text-muted)">Ticket</td><td style="color:var(--text-muted)">Acceptance criteria</td><td style="color:var(--text-dim)">Created → Done</td></tr>
          <tr><td>GitHub Issue</td><td style="color:var(--text-muted)">Issue body</td><td style="color:var(--text-muted)">Checklist items</td><td style="color:var(--text-dim)">Opened → closed</td></tr>
          <tr><td>Markdown</td><td style="color:var(--text-muted)">The file</td><td style="color:var(--text-muted)">Bullet points</td><td style="color:var(--text-dim)">Created → verified</td></tr>
          <tr><td>User prompt</td><td style="color:var(--text-muted)">The prompt text</td><td style="color:var(--text-muted)">Implicit (single req)</td><td style="color:var(--text-dim)">Prompt → accepted</td></tr>
        </tbody>
      </table>
    </div>

    <!-- ── Tiers ── -->
    <!-- ── Supporting Metrics ── -->
    <div id="spec-supporting" class="spec-block fade-in">
      <h3>Supporting Metrics</h3>
      <p>The five headline metrics tell you <em>what's happening</em>. The supporting metrics tell you <em>why</em>. Every supporting metric feeds at least one headline metric — when a headline goes red, you drill into the supporting metrics to find the cause.</p>

      <div class="spec-supporting-card">
        <h4>Token Usage</h4>
        <div class="feeds">Feeds → Recovery Efficiency, Feature Throughput</div>
        <p>Total input tokens, output tokens, cost per deliverable. If an agent uses 50k tokens on a deliverable that should take 10k, the extra 40k is recovery overhead. It also contextualises Feature Throughput — are you shipping more because the agent is efficient, or because it's brute-forcing with expensive models? Token cost per deliverable is the unit economics metric teams will care about most once they're past the "does it work" phase.</p>
      </div>

      <div class="spec-supporting-card">
        <h4>Tool Call Count</h4>
        <div class="feeds">Feeds → Recovery Efficiency, Resolution Latency</div>
        <p>Counts by type: Write, Edit, Bash, Read, etc. A healthy deliverable has a predictable ratio of reads to writes. If you see 40 Read calls and 2 Writes, the agent spent most of its time searching. If you see 15 Write calls and 12 Edit calls on the same files, it's rewriting its own work. The pattern tells you where the agent is struggling.</p>
      </div>

      <div class="spec-supporting-card">
        <h4>Phase Duration</h4>
        <div class="feeds">Feeds → Resolution Latency</div>
        <p>Time spent in each phase: propose, specs, design, tasks, apply, verify. This decomposes Resolution Latency into its parts. A 4-hour deliverable where 3.5 hours was in <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">apply</code> is very different from one where 2 hours was human review during <code style="color:var(--glow);font-family:var(--mono);font-size:0.85em;">verify</code>. This is where you find the bottleneck — is the agent slow, or is the human slow to review?</p>
      </div>

      <div class="spec-supporting-card">
        <h4>Apply Iterations</h4>
        <div class="feeds">Feeds → Delivery Completeness, Recovery Efficiency</div>
        <p>How many times the apply phase ran before acceptance. The most direct indicator feeding Delivery Completeness and Recovery Efficiency. First-time-right deliverables score higher on conformance (via the iteration penalty) and have zero recovery overhead. Tracking the count over time tells you if your agent is getting better or worse.</p>
      </div>

      <div class="spec-supporting-card">
        <h4>Recovery Attempts</h4>
        <div class="feeds">Feeds → Recovery Efficiency</div>
        <p>Count of rework cycles within an apply iteration — different from apply iterations. An apply iteration is "the agent stopped, human said try again." A recovery attempt is "the agent hit an error and self-corrected within a single run." High recovery attempts with eventual success means the agent is resilient but inefficient. High recovery attempts with failure means it's thrashing.</p>
      </div>

      <div class="spec-supporting-card">
        <h4>Tasks Completed vs Total</h4>
        <div class="feeds">Feeds → Delivery Completeness</div>
        <p>From the spec's task checklist. The raw input to the functional completeness dimension of Delivery Completeness. Useful on its own as a progress metric during execution — it answers "how far did the agent get" for both in-progress and failed deliverables.</p>
      </div>

      <div class="spec-supporting-card">
        <h4>Failure Type Distribution</h4>
        <div class="feeds">Feeds → Deliverable Failure Rate</div>
        <p>Breakdown across: spec_misunderstanding, hallucination, infinite_loop, tool_failure, constraint_violation, incomplete, regression. Categorises <em>why</em> deliverables fail, which the Deliverable Failure Rate alone can't tell you. A 12% failure rate means very different things if it's all tool failures (infrastructure problem) versus all hallucinations (model problem). This is the metric that tells you where to invest.</p>
      </div>

      <div class="spec-supporting-card">
        <h4>Human Intervention Count</h4>
        <div class="feeds">Feeds → Recovery Efficiency, Delivery Completeness</div>
        <p>Times a human had to step in during execution. An agent that completes every deliverable but needs 5 human nudges per run isn't really autonomous. This metric tracks the journey toward full autonomy.</p>
      </div>

      <div class="spec-supporting-card">
        <h4>Complexity Distribution</h4>
        <div class="feeds">Feeds → Feature Throughput, Resolution Latency</div>
        <p>Trivial/simple/moderate/complex breakdown of deliverables. Contextualises Feature Throughput and Resolution Latency. Shipping 10 trivial deliverables/day is not the same as shipping 2 complex ones. Without this, you can game throughput by splitting work into tiny pieces.</p>
      </div>

      <h4>The Relationship Map</h4>
      <p>Every supporting metric feeds at least one headline metric, and most feed two. Look at the five headlines on a dashboard — when one goes red, drill into the supporting metrics to find the cause.</p>
      <div class="spec-relationship-map"><span class="supporting">Token Usage</span> <span class="connector">──────────┐</span>
<span class="supporting">Tool Call Count</span> <span class="connector">──────┼──→</span> <span class="headline">Recovery Efficiency</span>
<span class="supporting">Recovery Attempts</span> <span class="connector">────┘</span>
                           <span class="connector">↕</span>
<span class="supporting">Phase Duration</span> <span class="connector">───────────→</span> <span class="headline">Resolution Latency</span>
                           <span class="connector">↕</span>
<span class="supporting">Apply Iterations</span> <span class="connector">─────┐</span>
<span class="supporting">Tasks Completed</span> <span class="connector">──────┼──→</span> <span class="headline">Delivery Completeness</span>
<span class="supporting">Human Interventions</span> <span class="connector">──┘</span>
                           <span class="connector">↕</span>
<span class="supporting">Failure Type</span> <span class="connector">─────────────→</span> <span class="headline">Deliverable Failure Rate</span>
                           <span class="connector">↕</span>
<span class="supporting">Complexity Distribution</span> <span class="connector">──→</span> <span class="headline">Feature Throughput</span></div>
    </div>

    <!-- ── Tiers ── -->
    <div id="spec-tiers" class="spec-block fade-in">
      <h3>Performance Tiers</h3>
      <p>Summary of all performance tiers across the five metrics. Tier classification uses the most recent rolling window — recommended default is 7 days or 20 deliverables, whichever comes first.</p>
      <table class="spec-table">
        <thead><tr><th>Metric</th><th class="hl">Elite</th><th>High</th><th>Medium</th><th>Low</th></tr></thead>
        <tbody>
          <tr><td>Feature Throughput</td><td class="hl">≥3/day</td><td style="color:var(--text-muted)">≥1/day</td><td style="color:var(--text-muted)">≥1/week</td><td style="color:var(--text-dim)">&lt;1/week</td></tr>
          <tr><td>Resolution Latency</td><td class="hl">&lt;1 hour</td><td style="color:var(--text-muted)">&lt;4 hours</td><td style="color:var(--text-muted)">&lt;1 day</td><td style="color:var(--text-dim)">≥1 day</td></tr>
          <tr><td>Deliverable Failure Rate</td><td class="hl">&lt;5%</td><td style="color:var(--text-muted)">&lt;10%</td><td style="color:var(--text-muted)">&lt;15%</td><td style="color:var(--text-dim)">≥15%</td></tr>
          <tr><td>Recovery Efficiency</td><td class="hl">&lt;5%</td><td style="color:var(--text-muted)">&lt;10%</td><td style="color:var(--text-muted)">&lt;20%</td><td style="color:var(--text-dim)">≥20%</td></tr>
          <tr><td>Delivery Completeness</td><td class="hl">≥95%</td><td style="color:var(--text-muted)">≥85%</td><td style="color:var(--text-muted)">≥70%</td><td style="color:var(--text-dim)">&lt;70%</td></tr>
        </tbody>
      </table>
    </div>

  </div>
</section>

<!-- ═══════════ IMPLEMENTATION ═══════════ -->
<section id="implementation">
  <div class="container">
    <span class="label">Get involved</span>
    <h2>This is a proposal — help shape it</h2>
    <p>AURA is an early draft, not a finished product. The specification, metrics, and data model are open for discussion. Read it, challenge it, and help make it useful.</p>
    <div style="margin-top: 40px; display: flex; gap: 16px; flex-wrap: wrap;">
      <a href="https://github.com/orgs/aura-metrics/discussions" class="btn btn-primary" target="_blank" rel="noopener">Join the discussion →</a>
      <a href="https://github.com/aura-metrics/aura-metrics-specification" class="btn btn-ghost" target="_blank" rel="noopener">View on GitHub</a>
    </div>
  </div>
</section>

<!-- ═══════════ ARCHITECTURE ═══════════ -->
<section id="architecture">
  <div class="container">
    <span class="label">Architecture</span>
    <h2>Built on OpenTelemetry</h2>
    <p>AURA extends OTel's GenAI semantic conventions. Your existing infrastructure, exporters, and backends all work.</p>
    <div class="arch-pipeline fade-in">
      <div class="arch-step"><span class="tag you">YOUR CODE</span><span class="desc">LangChain · CrewAI · AutoGen · PydanticAI · custom</span></div>
      <div class="arch-conn"></div>
      <div class="arch-step"><span class="tag aura">AURA SDK</span><span class="desc">Deliverable lifecycle · Delivery completeness · Failure classification · Recovery tracking</span></div>
      <div class="arch-conn"></div>
      <div class="arch-step"><span class="tag otel">OTEL SDK</span><span class="desc">Traces · Metrics · Events</span></div>
      <div class="arch-conn"></div>
      <div class="arch-step"><span class="tag otel">OTEL COLLECTOR</span><span class="desc">AURA processor · Spanmetrics · Export to any backend</span></div>
      <div class="arch-conn"></div>
      <div class="arch-step"><span class="tag infra">BACKEND</span><span class="desc">Grafana · Datadog · Honeycomb · Jaeger · any OTLP-compatible</span></div>
    </div>
  </div>
</section>

<!-- ═══════════ SPECS ═══════════ -->
<section id="specs">
  <div class="container">
    <span class="label">Bring your own spec framework</span>
    <h2>Works with any spec framework</h2>
    <p>AURA measures how well agents deliver against specs. It doesn't care how those specs are written. Use whatever fits your workflow.</p>

    <div class="problem-grid fade-in" style="margin-top: 40px;">
      <div class="problem-card" style="border-color: var(--glow-dim);">
        <div class="num" style="color:var(--glow);">RECOMMENDED</div>
        <h3><a href="https://github.com/Fission-AI/OpenSpec" style="color:var(--glow); text-decoration:none;">OpenSpec</a></h3>
        <p>Spec-driven development for AI coding assistants. Each change gets a structured folder — proposal, requirements, design, tasks. AURA reads the requirements and measures conformance. The example in this repo uses OpenSpec.</p>
      </div>
      <div class="problem-card">
        <div class="num">ALTERNATIVE</div>
        <h3><a href="https://github.com/github/spec-kit" style="color:var(--text); text-decoration:none;">spec-kit</a> <span style="color:var(--text-dim); font-family:var(--mono); font-size:0.7rem;">by GitHub</span></h3>
        <p>A thorough toolkit for spec-driven development with phase gates and structured templates. Heavier than OpenSpec, well-suited for enterprise teams that need more process.</p>
      </div>
      <div class="problem-card">
        <div class="num">ALTERNATIVE</div>
        <h3>Kiro, Linear, Jira, Notion…</h3>
        <p>A spec doesn't need a framework. A Jira ticket with acceptance criteria, a Notion doc with requirements, or even a plain Markdown file — all work.</p>
      </div>
      <div class="problem-card">
        <div class="num">THE PRINCIPLE</div>
        <h3>More explicit spec → more useful score</h3>
        <p>A vague prompt gives you a binary signal. A structured spec with 5 explicit requirements gives you a precise conformance gradient. AURA rewards specificity.</p>
      </div>
    </div>
  </div>
</section>

<!-- ═══════════ PLUGINS ═══════════ -->
<section id="plugins">
  <div class="container">
    <span class="label">Bring your own agent</span>
    <h2>Plugins</h2>
    <p>Integrate AURA into your agent toolchain using one of the available plugins.</p>
    <div class="plugins-grid" style="margin-top: 40px;">
      <div class="plugin-card">
        <div class="plugin-card-label">Plugin</div>
        <h3>Claude Code</h3>
        <p>Instruments Claude Code agent sessions with AURA metrics. Tracks deliverables, phases, and tool calls automatically via Claude Code hooks, emitting OpenTelemetry spans to your collector.</p>
        <a href="https://github.com/aura-metrics/aura-metrics-claude-code-plugin" class="plugin-link" target="_blank" rel="noopener">
          <svg width="14" height="14" viewBox="0 0 16 16" fill="currentColor"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/></svg>
          aura-metrics-claude-code-plugin →
        </a>
      </div>
    </div>
  </div>
</section>

<!-- ═══════════ ORIGIN ═══════════ -->
<section id="origin">
  <div class="container">
    <span class="label">Origin</span>
    <h2>Where AURA came from</h2>
    <p>AURA grew out of work on <strong style="color:var(--text)">AgentEx</strong> — the idea that the developer experience problems we spent a decade solving for humans (slow feedback loops, environment drift, deployment-gated testing) hit AI agents even harder. A human waiting three minutes for a deploy can context-switch. An agent just burns tokens doing nothing. The same fixes accelerate both, but for agents the shift is qualitative, not just quantitative.</p>
    <p style="margin-top:20px;">I'm <a href="https://www.linkedin.com/in/eamonnfaherty/" target="_blank" style="color:var(--green)">Eamonn Faherty</a>. I've been working on improving the developer experience for agents to improve the developer experience for the humans using them. Part of that portfolio is <a href="https://local-web-services.github.io/" target="_blank" style="color:var(--green)">Local Web Services</a> — a tool that reads your AWS CDK cloud assembly and recreates your entire application locally, giving agents (and humans) a tight inner loop measured in seconds instead of minutes.</p>
    <p style="margin-top:20px;">While building it, I kept asking the same question: <em>how do I know the agents are actually getting better?</em> I needed a way to measure throughput, stability, and quality — something like DORA, but for agent deliverables. That's how AURA started. You can read more about the AgentEx concept in <a href="https://medium.com/@eamonn.faherty_58176/agentex-the-problems-we-solved-for-devex-are-worth-more-for-agents-d7273094dad1" target="_blank" style="color:var(--green)">the original article</a>.</p>
  </div>
</section>

<!-- ═══════════ CTA ═══════════ -->
<section class="cta-section" id="start">
  <div class="container">
    <span class="label">Get involved</span>
    <h2>Help define the standard</h2>
    <p>AURA is a draft proposal. The goal is to establish a shared standard for measuring AI agent performance. Your input shapes what it becomes.</p>
    <div class="cta-actions">
      <a href="https://github.com/orgs/aura-metrics/discussions" class="btn btn-primary" target="_blank" rel="noopener">Join the discussion →</a>
      <a href="#specification" class="btn btn-ghost">Read the spec</a>
    </div>
  </div>
</section>

<footer>
  <div class="container">
    <p><strong style="color:var(--text)">AURA</strong> — DORA for pipelines. AURA for agents.<br>Open framework · Built on <a href="https://opentelemetry.io">OpenTelemetry</a></p>
  </div>
</footer>

<script>
const observer = new IntersectionObserver(
  entries => entries.forEach(e => { if (e.isIntersecting) e.target.classList.add('visible'); }),
  { threshold: 0.1, rootMargin: '0px 0px -40px 0px' }
);
document.querySelectorAll('.fade-in').forEach(el => observer.observe(el));

function showSpec(btn, id) {
  btn.closest('.spec-nav').querySelectorAll('button').forEach(b => b.classList.remove('active'));
  btn.classList.add('active');
  document.querySelectorAll('.spec-block').forEach(b => b.classList.remove('active'));
  document.getElementById(id).classList.add('active');
}
</script>
</body>
</html>
