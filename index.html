<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AURA — DORA for pipelines. AURA for agents.</title>
<meta name="description" content="AURA: Five key metrics for AI agent performance, built on OpenTelemetry. Five key metrics for AI agent performance, built on OpenTelemetry.">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,400;0,500;0,600;1,400;1,500&family=DM+Mono:wght@400;500&family=Outfit:wght@300;400;500;600&display=swap" rel="stylesheet">
<style>
:root {
  --bg: #08080c;
  --bg-raised: #0e0e14;
  --bg-card: #12121a;
  --bg-card-hover: #181822;
  --border: #222233;
  --border-subtle: #181828;
  --text: #e4e2ef;
  --text-muted: #9490a8;
  --text-dim: #5c5872;
  --glow: #4ADE80;
  --glow-bright: #6EE7A0;
  --glow-dim: #22C55E;
  --glow-bg: rgba(74, 222, 128, 0.05);
  --glow-bg-strong: rgba(74, 222, 128, 0.10);
  --warm: #ffd6a0;
  --red: #ff6b8a;
  --green: #7aefb2;
  --blue: #7ab8ef;
  --serif: 'Cormorant Garamond', Georgia, serif;
  --sans: 'Outfit', -apple-system, sans-serif;
  --mono: 'DM Mono', 'SF Mono', monospace;
}

*, *::before, *::after { margin: 0; padding: 0; box-sizing: border-box; }
html { scroll-behavior: smooth; -webkit-font-smoothing: antialiased; }

body {
  font-family: var(--sans);
  background: var(--bg);
  color: var(--text);
  line-height: 1.65;
  font-size: 16px;
  overflow-x: hidden;
}

::selection { background: var(--glow); color: var(--bg); }

.container { max-width: 1100px; margin: 0 auto; padding: 0 32px; }
section { padding: 100px 0; position: relative; }
section + section { border-top: 1px solid var(--border-subtle); }

h1, h2, h3 { font-family: var(--serif); font-weight: 400; }
h1 { font-size: clamp(3.2rem, 8vw, 6rem); line-height: 1.05; letter-spacing: -0.02em; }
h2 { font-size: clamp(2rem, 4vw, 3.2rem); line-height: 1.15; margin-bottom: 20px; letter-spacing: -0.01em; }
h3 { font-size: 1.5rem; line-height: 1.3; margin-bottom: 12px; }
p { color: var(--text-muted); font-size: 1.05rem; max-width: 620px; font-weight: 300; }
p + p { margin-top: 16px; }

.label {
  font-family: var(--mono);
  font-size: 0.7rem;
  letter-spacing: 0.14em;
  text-transform: uppercase;
  color: var(--glow-dim);
  margin-bottom: 16px;
  display: block;
}

/* ── Nav ── */
nav {
  position: fixed; top: 0; left: 0; right: 0; z-index: 100;
  padding: 16px 32px;
  display: flex; justify-content: space-between; align-items: center;
  background: rgba(8,8,12,0.88); backdrop-filter: blur(16px);
  border-bottom: 1px solid var(--border-subtle);
}
nav .logo {
  font-family: var(--serif); font-size: 1.3rem; font-weight: 500;
  color: var(--text); text-decoration: none;
}
nav .logo span { color: var(--glow); }
nav .nav-links { display: flex; gap: 28px; list-style: none; }
nav .nav-links a {
  font-family: var(--mono); font-size: 0.72rem; color: var(--text-dim);
  text-decoration: none; letter-spacing: 0.05em; transition: color 0.2s;
}
nav .nav-links a:hover { color: var(--glow); }

/* ── Hero ── */
.hero {
  min-height: 100vh; display: flex; flex-direction: column;
  justify-content: center; padding: 120px 0 80px; position: relative;
}
.hero::before {
  content: ''; position: absolute;
  top: 10%; left: 50%; transform: translateX(-50%);
  width: 800px; height: 800px;
  background: radial-gradient(circle, rgba(74,222,128,0.06) 0%, rgba(74,222,128,0.02) 30%, transparent 70%);
  pointer-events: none;
}
.hero::after {
  content: ''; position: absolute;
  bottom: 0; left: 0; right: 0; height: 1px;
  background: linear-gradient(90deg, transparent, var(--glow-dim), transparent);
  opacity: 0.3;
}

.hero-eyebrow {
  font-family: var(--mono); font-size: 0.78rem;
  color: var(--glow-dim); letter-spacing: 0.08em;
  margin-bottom: 32px;
}

h1 .glow {
  color: var(--glow);
  text-shadow: 0 0 60px rgba(74,222,128,0.25);
}

.hero-sub {
  font-family: var(--serif); font-size: 1.45rem; font-style: italic;
  color: var(--text-muted); max-width: 520px; line-height: 1.5;
  margin: 28px 0 48px; font-weight: 400;
}

.hero-cta { display: flex; gap: 16px; flex-wrap: wrap; }

.btn {
  display: inline-flex; align-items: center; gap: 8px;
  padding: 14px 28px; border-radius: 6px;
  font-family: var(--mono); font-size: 0.8rem;
  text-decoration: none; letter-spacing: 0.03em;
  transition: all 0.25s ease; cursor: pointer; border: none;
}
.btn-primary {
  background: var(--glow); color: var(--bg);
}
.btn-primary:hover {
  background: var(--glow-bright);
  box-shadow: 0 4px 32px rgba(74,222,128,0.3);
  transform: translateY(-1px);
}
.btn-ghost {
  background: transparent; color: var(--text-muted);
  border: 1px solid var(--border);
}
.btn-ghost:hover { border-color: var(--glow-dim); color: var(--glow); }

/* ── Problem ── */
.problem-grid {
  display: grid; grid-template-columns: 1fr 1fr;
  gap: 20px; margin-top: 48px;
}
.problem-card {
  padding: 32px; border: 1px solid var(--border-subtle);
  border-radius: 10px; background: var(--bg-card);
  transition: border-color 0.3s;
}
.problem-card:hover { border-color: var(--border); }
.problem-card .num {
  font-family: var(--mono); font-size: 0.65rem;
  color: var(--text-dim); letter-spacing: 0.12em; margin-bottom: 16px;
}
.problem-card h3 { color: var(--text); font-family: var(--sans); font-weight: 500; font-size: 1.05rem; }
.problem-card p { font-size: 0.92rem; color: var(--text-dim); margin-top: 8px; }

/* ── Insight ── */
.insight-box {
  background: var(--bg-card); border: 1px solid var(--border);
  border-radius: 14px; padding: 56px; margin-top: 48px;
  position: relative; overflow: hidden;
}
.insight-box::before {
  content: ''; position: absolute; top: 0; left: 0; right: 0; height: 1px;
  background: linear-gradient(90deg, transparent, var(--glow), transparent);
}
.insight-box h3 { font-size: 1.9rem; color: var(--text); margin-bottom: 20px; max-width: 560px; }
.hierarchy {
  margin-top: 36px; font-family: var(--mono); font-size: 0.82rem;
  line-height: 2; color: var(--text-muted);
  background: var(--bg); border-radius: 8px; padding: 24px 28px;
  border: 1px solid var(--border-subtle);
}
.hierarchy .hl { color: var(--glow); }
.hierarchy .dim { color: var(--text-dim); }

/* ── Metrics ── */
.metrics-header { text-align: center; max-width: 680px; margin: 0 auto 64px; }
.metrics-header p { margin: 0 auto; }

.metrics-grid {
  display: grid; grid-template-columns: repeat(3, 1fr);
  gap: 1px; background: var(--border-subtle);
  border-radius: 14px; overflow: hidden;
}
.metrics-grid.two-col {
  grid-template-columns: repeat(2, 1fr);
  max-width: 733px; margin: 1px auto 0;
}
.metric-card {
  background: var(--bg-card); padding: 36px 32px;
  transition: background 0.2s;
}
.metric-card:hover { background: var(--bg-card-hover); }
.metric-number {
  font-family: var(--mono); font-size: 0.62rem;
  color: var(--text-dim); letter-spacing: 0.15em;
  text-transform: uppercase; margin-bottom: 18px;
}
.metric-name {
  font-family: var(--serif); font-size: 1.55rem;
  color: var(--text); margin-bottom: 4px;
}
.metric-analog {
  font-family: var(--mono); font-size: 0.7rem;
  color: var(--glow-dim); margin-bottom: 14px;
}
.metric-desc {
  font-size: 0.9rem; color: var(--text-dim);
  line-height: 1.55; max-width: 100%;
}
.tiers { margin-top: 18px; display: flex; flex-direction: column; gap: 5px; }
.tier {
  display: flex; justify-content: space-between; align-items: center;
  font-family: var(--mono); font-size: 0.7rem;
}
.tier-label { color: var(--text-dim); }
.tier-value { color: var(--text-muted); }
.tier.elite .tier-label { color: var(--glow); }
.tier.elite .tier-value { color: var(--glow); }

/* ── Conformance dimensions ── */
.dimension-grid {
  display: grid; grid-template-columns: repeat(4, 1fr);
  gap: 1px; background: var(--border-subtle);
  border-radius: 10px; overflow: hidden; margin-top: 32px;
}
.dimension { background: var(--bg-card); padding: 28px 20px; text-align: center; }
.dimension-weight { font-family: var(--serif); font-size: 2.2rem; color: var(--glow); margin-bottom: 4px; }
.dimension-name { font-size: 0.85rem; font-weight: 500; color: var(--text); margin-bottom: 8px; }
.dimension-desc { font-size: 0.78rem; color: var(--text-dim); line-height: 1.4; }

/* ── Comparison ── */
.comparison { margin-top: 48px; overflow-x: auto; }
.comparison table { width: 100%; border-collapse: collapse; font-size: 0.9rem; }
.comparison th {
  font-family: var(--mono); font-size: 0.68rem; letter-spacing: 0.1em;
  text-transform: uppercase; color: var(--text-dim); text-align: left;
  padding: 14px 20px; border-bottom: 1px solid var(--border);
}
.comparison td {
  padding: 14px 20px; border-bottom: 1px solid var(--border-subtle);
  color: var(--text-muted); vertical-align: top; font-weight: 300;
}
.comparison tr td:first-child { color: var(--text); font-weight: 400; }
.comparison .glow-cell { color: var(--glow); }

/* ── Architecture ── */
.arch-diagram {
  margin-top: 48px; background: var(--bg-card);
  border: 1px solid var(--border-subtle); border-radius: 10px;
  padding: 44px; overflow-x: auto;
}
.arch-layer { display: flex; align-items: center; gap: 16px; padding: 14px 0; }
.arch-layer + .arch-layer { border-top: 1px dashed var(--border-subtle); }
.arch-layer .tag {
  font-family: var(--mono); font-size: 0.7rem;
  padding: 4px 12px; border-radius: 4px; white-space: nowrap; flex-shrink: 0;
}
.arch-layer .tag.you { background: rgba(74,222,128,0.10); color: var(--glow); }
.arch-layer .tag.aura { background: rgba(74,222,128,0.10); color: var(--glow); }
.arch-layer .tag.otel { background: rgba(122,184,239,0.10); color: var(--blue); }
.arch-layer .tag.infra { background: rgba(122,239,178,0.10); color: var(--green); }
.arch-layer .desc { font-size: 0.88rem; color: var(--text-muted); font-weight: 300; }
.arch-arrow { text-align: center; padding: 6px 0; color: var(--text-dim); font-size: 0.85rem; }

/* ── Philosophy ── */
.principles { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 48px; }
.principle {
  padding: 28px 32px; border-left: 2px solid var(--border-subtle);
  transition: border-color 0.3s;
}
.principle:hover { border-color: var(--glow); }
.principle-num {
  font-family: var(--mono); font-size: 0.62rem;
  color: var(--glow-dim); letter-spacing: 0.12em; margin-bottom: 12px;
}
.principle h3 { font-family: var(--sans); font-size: 1rem; font-weight: 500; color: var(--text); margin-bottom: 8px; }
.principle p { font-size: 0.9rem; color: var(--text-dim); }

/* ── CTA ── */
.cta-section { text-align: center; padding: 120px 0; position: relative; }
.cta-section::before {
  content: ''; position: absolute;
  top: 50%; left: 50%; transform: translate(-50%, -50%);
  width: 600px; height: 400px;
  background: radial-gradient(ellipse, rgba(74,222,128,0.04) 0%, transparent 70%);
  pointer-events: none;
}
.cta-section h2 { margin-bottom: 16px; }
.cta-section p { margin: 0 auto 40px; text-align: center; }
.cta-actions { display: flex; justify-content: center; gap: 16px; flex-wrap: wrap; }

/* ── Footer ── */
footer { border-top: 1px solid var(--border-subtle); padding: 40px 0; text-align: center; }
footer p { font-size: 0.85rem; color: var(--text-dim); margin: 0 auto; }
footer a { color: var(--text-muted); text-decoration: none; }
footer a:hover { color: var(--glow); }

/* ── Animations ── */
.fade-in { opacity: 0; transform: translateY(16px); transition: opacity 0.7s ease, transform 0.7s ease; }
.fade-in.visible { opacity: 1; transform: translateY(0); }

/* ── Responsive ── */
@media (max-width: 768px) {
  .container { padding: 0 20px; }
  section { padding: 64px 0; }
  .problem-grid, .metrics-grid, .metrics-grid.two-col, .principles { grid-template-columns: 1fr; }
  .dimension-grid { grid-template-columns: repeat(2, 1fr); }
  .insight-box { padding: 28px; }
  nav .nav-links { display: none; }
  .hero { padding: 100px 0 60px; min-height: auto; }
}
</style>
</head>
<body>

<nav>
  <a href="#" class="logo"><span>AURA</span></a>
  <ul class="nav-links">
    <li><a href="#insight">Insight</a></li>
    <li><a href="#metrics">Metrics</a></li>
    <li><a href="#specs">Specs</a></li>
    <li><a href="#architecture">Architecture</a></li>
    <li><a href="#start">Get Started</a></li>
  </ul>
</nav>

<!-- ═══════════ HERO ═══════════ -->
<section class="hero">
  <div class="container">
    <div class="hero-eyebrow">DORA for pipelines. AURA for agents.</div>
    <h1>
      See what your agents<br>
      <span class="glow">actually deliver</span>
    </h1>
    <p class="hero-sub">
      DORA for pipelines. AURA for agents.<br>
      Five metrics. Built on OpenTelemetry.
    </p>
    <div class="hero-cta">
      <a href="#metrics" class="btn btn-primary">The five metrics ↓</a>
      <a href="#start" class="btn btn-ghost">Get the SDK</a>
    </div>
  </div>
</section>

<!-- ═══════════ PROBLEM ═══════════ -->
<section id="problem">
  <div class="container">
    <span class="label">The problem</span>
    <h2>Your agents are black boxes</h2>
    <p>DORA gave software delivery four clear metrics. AI agents have nothing. Every team invents their own, making it impossible to benchmark or improve.</p>
    <div class="problem-grid fade-in">
      <div class="problem-card">
        <div class="num">01</div>
        <h3>No standard metrics</h3>
        <p>Is the agent delivering what was asked? How would you know? Every team tracks something different.</p>
      </div>
      <div class="problem-card">
        <div class="num">02</div>
        <h3>Task ≠ Value</h3>
        <p>Measuring tool calls is like measuring commits instead of deployments. Activity isn't delivery.</p>
      </div>
      <div class="problem-card">
        <div class="num">03</div>
        <h3>No quality gradient</h3>
        <p>Binary pass/fail doesn't capture reality. Two agents can "complete" a feature — one nails it, the other barely passes.</p>
      </div>
      <div class="problem-card">
        <div class="num">04</div>
        <h3>Recovery is invisible</h3>
        <p>When an agent fails mid-task, does it self-correct or spiral in a loop burning tokens? You can't tell until you check the bill.</p>
      </div>
    </div>
  </div>
</section>

<!-- ═══════════ INSIGHT ═══════════ -->
<section id="insight">
  <div class="container">
    <span class="label">Key insight</span>
    <h2>Measure deliverables, not tasks</h2>
    <p>DORA measures <strong style="color:var(--text)">deployments</strong>, not commits. AURA applies the same principle: measure the unit of value delivered against a specification.</p>
    <div class="insight-box fade-in">
      <h3>A task is a commit.<br>A deliverable is a deployment.</h3>
      <p>An agent might complete 50 tasks in pursuit of one thing a user cares about. That one thing, verified against a spec, is what AURA measures.</p>
      <div class="hierarchy">
        <span class="hl">Deliverable</span> <span class="dim">← unit of measurement for AURA</span><br>
        ├── <span class="hl">Spec</span> <span class="dim">← what was requested (acceptance criteria)</span><br>
        ├── Plan <span class="dim">← how the agent approaches it</span><br>
        ├── Tasks <span class="dim">← individual steps</span><br>
        │&nbsp;&nbsp;&nbsp;├── LLM calls<br>
        │&nbsp;&nbsp;&nbsp;├── Tool calls<br>
        │&nbsp;&nbsp;&nbsp;└── Reasoning steps<br>
        └── <span class="hl">Outcome</span><br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└── <span class="hl">Spec Conformance</span> <span class="dim">← how well did it match?</span>
      </div>
    </div>
  </div>
</section>

<!-- ═══════════ WHY NOT DORA ═══════════ -->
<section>
  <div class="container" style="max-width:780px;">
    <span class="label">A natural question</span>
    <h2>Why not just use DORA?</h2>
    <p>DORA is excellent — if you're shipping software, you should be tracking it. AURA doesn't replace DORA. It fills a gap DORA was never designed to cover.</p>
    <p style="margin-top:20px;">DORA measures how well your <strong style="color:var(--text)">pipeline</strong> delivers code to production. It assumes a human wrote the code, a CI system tested it, and a deployment shipped it. AI agents don't have pipelines. They receive a request, reason, call tools, and produce output. The failure modes aren't broken builds — they're hallucinations, spec mismatches, and infinite loops. The quality question isn't "did it deploy safely?" but "did it do what was asked?"</p>
    <p style="margin-top:20px;">If your agents write code that flows through a DORA-measured pipeline, the two complement each other perfectly: <strong style="color:var(--text)">DORA measures the pipeline. AURA measures the agent.</strong></p>
  </div>
</section>

<!-- ═══════════ METRICS ═══════════ -->
<section id="metrics">
  <div class="container">
    <div class="metrics-header">
      <span class="label">The five metrics</span>
      <h2>Throughput · Stability · Quality</h2>
      <p>Like DORA, AURA captures the tension between speed and stability. Unlike DORA, it adds a quality dimension unique to AI.</p>
    </div>

    <div class="metrics-grid fade-in" style="margin-bottom:1px;">
      <div class="metric-card">
        <div class="metric-number">01 · Throughput</div>
        <div class="metric-name">Feature Throughput</div>
        <div class="metric-analog">↔ Deployment Frequency</div>
        <div class="metric-desc">Deliverables accepted per time period. Measures productivity at the level humans care about.</div>
        <div class="tiers">
          <div class="tier elite"><span class="tier-label">Elite</span><span class="tier-value">&gt;20 /day</span></div>
          <div class="tier"><span class="tier-label">High</span><span class="tier-value">5–20 /day</span></div>
          <div class="tier"><span class="tier-label">Medium</span><span class="tier-value">1–5 /day</span></div>
          <div class="tier"><span class="tier-label">Low</span><span class="tier-value">&lt;1 /day</span></div>
        </div>
      </div>
      <div class="metric-card">
        <div class="metric-number">02 · Throughput</div>
        <div class="metric-name">Resolution Latency</div>
        <div class="metric-analog">↔ Lead Time for Changes</div>
        <div class="metric-desc">Spec received to verified deliverable. Includes planning, execution, validation, and rework.</div>
        <div class="tiers">
          <div class="tier elite"><span class="tier-label">Elite</span><span class="tier-value">p50 &lt; 1m</span></div>
          <div class="tier"><span class="tier-label">High</span><span class="tier-value">p50 &lt; 5m</span></div>
          <div class="tier"><span class="tier-label">Medium</span><span class="tier-value">p50 &lt; 30m</span></div>
          <div class="tier"><span class="tier-label">Low</span><span class="tier-value">p50 &gt; 30m</span></div>
        </div>
      </div>
      <div class="metric-card">
        <div class="metric-number">03 · Stability</div>
        <div class="metric-name">Deliverable Failure Rate</div>
        <div class="metric-analog">↔ Change Failure Rate</div>
        <div class="metric-desc">Percentage of deliverables that fail spec, require human takeover, or are abandoned.</div>
        <div class="tiers">
          <div class="tier elite"><span class="tier-label">Elite</span><span class="tier-value">&lt;5%</span></div>
          <div class="tier"><span class="tier-label">High</span><span class="tier-value">5–15%</span></div>
          <div class="tier"><span class="tier-label">Medium</span><span class="tier-value">15–30%</span></div>
          <div class="tier"><span class="tier-label">Low</span><span class="tier-value">&gt;30%</span></div>
        </div>
      </div>
    </div>

    <div class="metrics-grid two-col fade-in">
      <div class="metric-card">
        <div class="metric-number">04 · Stability</div>
        <div class="metric-name">Recovery Efficiency</div>
        <div class="metric-analog">↔ Mean Time to Recovery</div>
        <div class="metric-desc">When things fail mid-delivery, how efficiently does the agent self-correct? Ratio of recovery overhead to total time.</div>
        <div class="tiers">
          <div class="tier elite"><span class="tier-label">Elite</span><span class="tier-value">&lt;10% overhead</span></div>
          <div class="tier"><span class="tier-label">High</span><span class="tier-value">10–25%</span></div>
          <div class="tier"><span class="tier-label">Medium</span><span class="tier-value">25–50%</span></div>
          <div class="tier"><span class="tier-label">Low</span><span class="tier-value">&gt;50%</span></div>
        </div>
      </div>
      <div class="metric-card" style="border-left: 2px solid var(--glow);">
        <div class="metric-number" style="color:var(--glow);">05 · Quality — Unique to AURA</div>
        <div class="metric-name">Spec Conformance</div>
        <div class="metric-analog">No DORA analog</div>
        <div class="metric-desc">How well did the deliverable satisfy the spec? A quality gradient between "barely acceptable" and "perfect."</div>
        <div class="tiers">
          <div class="tier elite"><span class="tier-label">Elite</span><span class="tier-value">&gt;0.95</span></div>
          <div class="tier"><span class="tier-label">High</span><span class="tier-value">0.80–0.95</span></div>
          <div class="tier"><span class="tier-label">Medium</span><span class="tier-value">0.60–0.80</span></div>
          <div class="tier"><span class="tier-label">Low</span><span class="tier-value">&lt;0.60</span></div>
        </div>
      </div>
    </div>

    <div style="margin-top: 48px;" class="fade-in">
      <h3 style="text-align:center; margin-bottom:8px;">Conformance Dimensions</h3>
      <p style="text-align:center; margin:0 auto;">Four weighted dimensions that capture how completely and accurately the agent delivered.</p>
      <div class="dimension-grid">
        <div class="dimension">
          <div class="dimension-weight">40%</div>
          <div class="dimension-name">Functional Completeness</div>
          <div class="dimension-desc">Did it do everything<br>the spec asked?</div>
        </div>
        <div class="dimension">
          <div class="dimension-weight">30%</div>
          <div class="dimension-name">Correctness</div>
          <div class="dimension-desc">Is the output factually<br>and logically right?</div>
        </div>
        <div class="dimension">
          <div class="dimension-weight">20%</div>
          <div class="dimension-name">Constraint Adherence</div>
          <div class="dimension-desc">Did it respect boundaries,<br>formats, and limits?</div>
        </div>
        <div class="dimension">
          <div class="dimension-weight">10%</div>
          <div class="dimension-name">Iteration Count</div>
          <div class="dimension-desc">How many attempts<br>to get it right?</div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ═══════════ COMPARISON ═══════════ -->
<section>
  <div class="container">
    <span class="label">Side by side</span>
    <h2>DORA → AURA</h2>
    <p>Same structure. Different domain. One new dimension.</p>
    <div class="comparison fade-in">
      <table>
        <thead><tr><th>Aspect</th><th>DORA</th><th>AURA</th></tr></thead>
        <tbody>
          <tr><td>Domain</td><td>Software delivery</td><td class="glow-cell">AI agent performance</td></tr>
          <tr><td>Unit</td><td>Deployment</td><td class="glow-cell">Deliverable (against spec)</td></tr>
          <tr><td>Throughput 1</td><td>Deployment Frequency</td><td class="glow-cell">Feature Throughput</td></tr>
          <tr><td>Throughput 2</td><td>Lead Time</td><td class="glow-cell">Resolution Latency</td></tr>
          <tr><td>Stability 1</td><td>Change Failure Rate</td><td class="glow-cell">Deliverable Failure Rate</td></tr>
          <tr><td>Stability 2</td><td>MTTR</td><td class="glow-cell">Recovery Efficiency</td></tr>
          <tr><td>Quality</td><td style="color:var(--text-dim)">—</td><td class="glow-cell">Spec Conformance</td></tr>
          <tr><td>Data source</td><td>CI/CD pipelines</td><td class="glow-cell">OpenTelemetry traces</td></tr>
        </tbody>
      </table>
    </div>
  </div>
</section>

<!-- ═══════════ SPECS ═══════════ -->
<section id="specs">
  <div class="container">
    <span class="label">Bring your own spec</span>
    <h2>Works with any spec framework</h2>
    <p>AURA measures how well agents deliver against specs. It doesn't care how those specs are written. Use whatever fits your workflow.</p>

    <div class="problem-grid fade-in" style="margin-top: 40px;">
      <div class="problem-card" style="border-color: var(--glow-dim);">
        <div class="num" style="color:var(--glow);">RECOMMENDED</div>
        <h3><a href="https://github.com/Fission-AI/OpenSpec" style="color:var(--glow); text-decoration:none;">OpenSpec</a></h3>
        <p>Spec-driven development for AI coding assistants. Each change gets a structured folder — proposal, requirements, design, tasks. AURA reads the requirements and measures conformance. The example in this repo uses OpenSpec.</p>
      </div>
      <div class="problem-card">
        <div class="num">ALTERNATIVE</div>
        <h3><a href="https://github.com/github/spec-kit" style="color:var(--text); text-decoration:none;">spec-kit</a> <span style="color:var(--text-dim); font-family:var(--mono); font-size:0.7rem;">by GitHub</span></h3>
        <p>A thorough toolkit for spec-driven development with phase gates and structured templates. Heavier than OpenSpec, well-suited for enterprise teams that need more process.</p>
      </div>
      <div class="problem-card">
        <div class="num">ALTERNATIVE</div>
        <h3>Kiro, Linear, Jira, Notion…</h3>
        <p>A spec doesn't need a framework. A Jira ticket with acceptance criteria, a Notion doc with requirements, or even a plain Markdown file — all work.</p>
      </div>
      <div class="problem-card">
        <div class="num">THE PRINCIPLE</div>
        <h3>More explicit spec → more useful score</h3>
        <p>A vague prompt gives you a binary signal. A structured spec with 5 explicit requirements gives you a precise conformance gradient. AURA rewards specificity.</p>
      </div>
    </div>
  </div>
</section>

<!-- ═══════════ ARCHITECTURE ═══════════ -->
<section id="architecture">
  <div class="container">
    <span class="label">Architecture</span>
    <h2>Built on OpenTelemetry</h2>
    <p>AURA extends OTel's GenAI semantic conventions. Your existing infrastructure, exporters, and backends all work.</p>
    <div class="arch-diagram fade-in">
      <div class="arch-layer"><span class="tag you">YOUR CODE</span><span class="desc">LangChain · CrewAI · AutoGen · PydanticAI · custom</span></div>
      <div class="arch-arrow">↓</div>
      <div class="arch-layer"><span class="tag aura">AURA SDK</span><span class="desc">Deliverable lifecycle · Spec conformance · Failure classification · Recovery tracking</span></div>
      <div class="arch-arrow">↓</div>
      <div class="arch-layer"><span class="tag otel">OTEL SDK</span><span class="desc">Traces · Metrics · Events</span></div>
      <div class="arch-arrow">↓</div>
      <div class="arch-layer"><span class="tag otel">OTEL COLLECTOR</span><span class="desc">AURA processor · Spanmetrics · Export to any backend</span></div>
      <div class="arch-arrow">↓</div>
      <div class="arch-layer"><span class="tag infra">BACKEND</span><span class="desc">Grafana · Datadog · Honeycomb · Jaeger · any OTLP-compatible</span></div>
    </div>
  </div>
</section>

<!-- ═══════════ PHILOSOPHY ═══════════ -->
<section>
  <div class="container">
    <span class="label">Philosophy</span>
    <h2>What AURA believes</h2>
    <div class="principles fade-in">
      <div class="principle"><div class="principle-num">01</div><h3>Measure deliverables, not tasks</h3><p>Tool calls are commits. Deliverables are deployments. Measure value.</p></div>
      <div class="principle"><div class="principle-num">02</div><h3>Speed, stability, and quality correlate</h3><p>The best agents are fast, reliable, and accurate. Optimizing one at the expense of others hides deeper problems.</p></div>
      <div class="principle"><div class="principle-num">03</div><h3>The spec is the source of truth</h3><p>Without a spec, you can't measure quality. AURA makes specs explicit.</p></div>
      <div class="principle"><div class="principle-num">04</div><h3>Metrics drive conversations</h3><p>Not leaderboards. Not punishments. Conversations about where to improve.</p></div>
      <div class="principle"><div class="principle-num">05</div><h3>Build on existing standards</h3><p>OTel GenAI semantic conventions. Your infrastructure already works.</p></div>
      <div class="principle"><div class="principle-num">06</div><h3>Start simple, go deep</h3><p>Five headline metrics tell the story. Supporting metrics tell you why.</p></div>
    </div>
  </div>
</section>

<!-- ═══════════ ORIGIN ═══════════ -->
<section>
  <div class="container" style="max-width:780px;">
    <span class="label">Origin</span>
    <h2>Where AURA came from</h2>
    <p>AURA grew out of work on <strong style="color:var(--text)">AgentEx</strong> — the idea that the developer experience problems we spent a decade solving for humans (slow feedback loops, environment drift, deployment-gated testing) hit AI agents even harder. A human waiting three minutes for a deploy can context-switch. An agent just burns tokens doing nothing. The same fixes accelerate both, but for agents the shift is qualitative, not just quantitative.</p>
    <p style="margin-top:20px;">I'm <a href="https://www.linkedin.com/in/eamonnfaherty/" target="_blank" style="color:var(--green)">Eamonn Faherty</a>. I've been working on improving the developer experience for agents to improve the developer experience for the humans using them. Part of that portfolio is <a href="https://local-web-services.github.io/" target="_blank" style="color:var(--green)">Local Web Services</a> — a tool that reads your AWS CDK cloud assembly and recreates your entire application locally, giving agents (and humans) a tight inner loop measured in seconds instead of minutes.</p>
    <p style="margin-top:20px;">While building it, I kept asking the same question: <em>how do I know the agents are actually getting better?</em> I needed a way to measure throughput, stability, and quality — something like DORA, but for agent deliverables. That's how AURA started. You can read more about the AgentEx concept in <a href="https://medium.com/@eamonn.faherty_58176/agentex-the-problems-we-solved-for-devex-are-worth-more-for-agents-d7273094dad1" target="_blank" style="color:var(--green)">the original article</a>.</p>
  </div>
</section>

<!-- ═══════════ CTA ═══════════ -->
<section class="cta-section" id="start">
  <div class="container">
    <span class="label">Get started</span>
    <h2>Start measuring in minutes</h2>
    <p>The AURA SDK is a single Python file. Drop it in, point it at an OTel Collector, and see your five metrics.</p>
    <div class="cta-actions">
      <a href="#" class="btn btn-primary" onclick="alert('Check the SDK files included with this page'); return false;">Get the SDK →</a>
      <a href="#" class="btn btn-ghost" onclick="alert('Check the concept doc included with this page'); return false;">Read the full spec</a>
    </div>
  </div>
</section>

<footer>
  <div class="container">
    <p><strong style="color:var(--text)">AURA</strong> — DORA for pipelines. AURA for agents.<br>Open framework · Built on <a href="https://opentelemetry.io">OpenTelemetry</a></p>
  </div>
</footer>

<script>
const observer = new IntersectionObserver(
  entries => entries.forEach(e => { if (e.isIntersecting) e.target.classList.add('visible'); }),
  { threshold: 0.1, rootMargin: '0px 0px -40px 0px' }
);
document.querySelectorAll('.fade-in').forEach(el => observer.observe(el));
</script>
</body>
</html>
